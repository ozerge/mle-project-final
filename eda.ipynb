{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "931310da",
   "metadata": {},
   "source": [
    "В данном ноутбуке проведены исследования по 1-2 шагам из README:\n",
    "\n",
    "    === ШАГ 1: Исследование данных ===\n",
    "        ЭТАП 1: Исследование и анализ данных о клиентах\n",
    "        ЭТАП 2: EDA\n",
    "        ЭТАП 3: Объеденение данных и FEATURE ENGINEERING  \n",
    "        ЭТАП 4: Сохранение данных\n",
    "       \n",
    "\n",
    "    === ШАГ 2: Подготовка инфраструктуры ===\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0596129",
   "metadata": {},
   "source": [
    "=== ШАГ 1: Исследование данных ===  \n",
    "ЭТАП 1: Исследование и анализ данных о клиентах  \n",
    "\n",
    "Загружаем библиотеки необходимые для выполнения кода ноутбука.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cabbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4834b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "# Пути и названия файлов заданы в виде параметров\n",
    "PATH_DATA = 'data'\n",
    "\n",
    "PATH_MODELS = 'models'\n",
    "MODEL_FILE = 'model.pkl'\n",
    "\n",
    "ASSETS_DIR = 'mlflow_server/eda_plots'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7553d3e1",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ[\"S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" \n",
    "os.environ[\"S3_BUCKET_NAME\"] = os.getenv(\"S3_BUCKET_NAME\") \n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") \n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f5eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_safe(file_name):\n",
    "    \"\"\"\n",
    "    загружает CSV файл с обработкой ошибок\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_name)\n",
    "        print(f\"УСПЕХ: {file_name} загружен\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ОШИБКА: Файл {file_name} не найден\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ОШИБКА при загрузке {file_name}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных с обработкой ошибок\n",
    "category_tree = load_data_safe(f'{PATH_DATA}/category_tree.csv')\n",
    "events = load_data_safe(f'{PATH_DATA}/events.csv')\n",
    "item_properties_part1 = load_data_safe(f'{PATH_DATA}/item_properties_part1.csv')\n",
    "item_properties_part2 = load_data_safe(f'{PATH_DATA}/item_properties_part2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7deee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведем основную информацию о каждом датасете\n",
    "print(\"=== category_tree ===\")\n",
    "category_tree.info()\n",
    "category_tree.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f72cf",
   "metadata": {},
   "source": [
    "`category_tree.csv` — таблица из двух столбцов: «родительская категория» и «дочерняя категория». Типичный способ представления таблицы в виде дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df2c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== events ===\")\n",
    "events.info()\n",
    "events.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b9f37",
   "metadata": {},
   "source": [
    "`events.csv` — таблица с логом событий:  \n",
    "- `timestamp` — временная метка события,  \n",
    "- `visitorid`— идентификатор пользователя,  \n",
    "- `event` — событие (просмотр, добавление в корзину, покупка),  \n",
    "- `itemid` — идентификатор товара,  \n",
    "- `transactionid` — идентификатор транзакции (покупки)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b2240",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== item_properties_part1 ===\")\n",
    "item_properties_part1.info()\n",
    "item_properties_part1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8791f9",
   "metadata": {},
   "source": [
    "`item_properties_part1.csv` — таблица со свойствами товаров:  \n",
    "- `timestamp` — временная метка добавления свойства,  \n",
    "- `itemid` — идентификатор товара,  \n",
    "- `property` — свойство товара,  \n",
    "- `value` — значение свойства.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c1ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== item_properties_part2 ===\")\n",
    "item_properties_part2.info()\n",
    "item_properties_part2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a21a4",
   "metadata": {},
   "source": [
    "`item_properties_part2.csv` — таблица со свойствами товаров:  \n",
    "- `timestamp` — временная метка добавления свойства,  \n",
    "- `itemid` — идентификатор товара,  \n",
    "- `property` — свойство товара,  \n",
    "- `value` — значение свойства.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8030c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединим item_properties_part1 и item_properties_part2 в один датафрейм\n",
    "item_properties = pd.concat([item_properties_part1, item_properties_part2], ignore_index=True)\n",
    "print(f\"Объединенная таблица item_properties: {item_properties.shape[0]:,} строк\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка на пропуски\n",
    "print(\" ПРОПУЩЕННЫЕ ЗНАЧЕНИЯ:\")\n",
    "print(f\"   - category_tree пропуски: {category_tree.isnull().sum().sum()}\")\n",
    "print(f\"   - events пропуски: {events.isnull().sum().sum()}\")\n",
    "print(f\"   - item_properties пропуски: {item_properties.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c88b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n ПРОВЕРКА ДУБЛИКАТОВ:\")\n",
    "\n",
    "# Полные дубликаты\n",
    "cat_duplicates = category_tree.duplicated().sum()\n",
    "events_duplicates = events.duplicated().sum()\n",
    "item_props_duplicates = item_properties.duplicated().sum()\n",
    "\n",
    "print(f\"   - category_tree: {cat_duplicates:,} полных дубликатов\")\n",
    "print(f\"   - events: {events_duplicates:,} полных дубликатов\") \n",
    "print(f\"   - item_properties: {item_props_duplicates:,} полных дубликатов\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da931bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ОЧИСТКА И ПОДГОТОВКА ДАННЫХ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Очистка дубликатов в events\n",
    "print(\"1. ОЧИСТКА ДУБЛИКАТОВ:\")\n",
    "initial_events_size = len(events)\n",
    "\n",
    "if events_duplicates > 0:\n",
    "    events = events.drop_duplicates()\n",
    "    print(f\"    Удалено {events_duplicates} полных дубликатов из events\")\n",
    "\n",
    "# Проверим частичные дубликаты в events (более опасные!)\n",
    "events_key_duplicates = events.duplicated(subset=['timestamp', 'visitorid', 'itemid', 'event']).sum()\n",
    "print(f\"   - events частичные дубликаты (ключевые поля): {events_key_duplicates:,}\")\n",
    "\n",
    "if events_key_duplicates > 0:\n",
    "    events = events.drop_duplicates(subset=['timestamp', 'visitorid', 'itemid', 'event'])\n",
    "    print(f\" Удалено {events_key_duplicates} частичных дубликатов из events\")\n",
    "\n",
    "print(f\" Размер events: {initial_events_size:,} → {len(events):,} строк\")\n",
    "\n",
    "# 2. Переименование столбцов в PEP8\n",
    "print(\"\\n2. ПЕРЕИМЕНОВАНИЕ СТОЛБЦОВ (PEP8):\")\n",
    "\n",
    "print(\"   До переименования:\")\n",
    "print(f\"   - category_tree: {list(category_tree.columns)}\")\n",
    "print(f\"   - events: {list(events.columns)}\")\n",
    "print(f\"   - item_properties: {list(item_properties.columns)}\")\n",
    "\n",
    "# Переименование согласно PEP8 (snake_case)\n",
    "category_tree = category_tree.rename(columns={\n",
    "    'categoryid': 'category_id',\n",
    "    'parentid': 'parent_id'\n",
    "})\n",
    "\n",
    "events = events.rename(columns={\n",
    "    'visitorid': 'visitor_id', \n",
    "    'itemid': 'item_id',\n",
    "    'transactionid': 'transaction_id'\n",
    "})\n",
    "\n",
    "item_properties = item_properties.rename(columns={\n",
    "    'itemid': 'item_id'\n",
    "})\n",
    "\n",
    "print(\"   После переименования:\")\n",
    "print(f\"   - category_tree: {list(category_tree.columns)}\")\n",
    "print(f\"   - events: {list(events.columns)}\")\n",
    "print(f\"   - item_properties: {list(item_properties.columns)}\")\n",
    "\n",
    "# 3. Детальный анализ пропусков\n",
    "print(\"\\n3. ДЕТАЛЬНЫЙ АНАЛИЗ ПРОПУСКОВ:\")\n",
    "\n",
    "# В events\n",
    "events_nulls = events.isnull().sum()\n",
    "print(f\"   - events:\")\n",
    "print(f\"     transaction_id: {events_nulls['transaction_id']:,} пропусков\")\n",
    "print(f\"     (это ожидаемо - пропуски для событий 'view' и 'addtocart')\")\n",
    "\n",
    "# В category_tree\n",
    "category_nulls = category_tree.isnull().sum()\n",
    "print(f\"   - category_tree:\")\n",
    "print(f\"     parent_id: {category_nulls['parent_id']:,} пропусков\")\n",
    "print(f\"     (это корневые категории - ожидаемо)\")\n",
    "\n",
    "# В item_properties\n",
    "item_props_nulls = item_properties.isnull().sum()\n",
    "print(f\"   - item_properties: {item_props_nulls.sum():,} пропусков\")\n",
    "\n",
    "# 4. Проверка целостности данных\n",
    "print(\"\\n4. ПРОВЕРКА ЦЕЛОСТНОСТИ ДАННЫХ:\")\n",
    "\n",
    "# В category_tree - проверка \"сиротских\" parent_id\n",
    "orphan_parents = set(category_tree['parent_id'].dropna()) - set(category_tree['category_id'])\n",
    "print(f\"   - category_tree 'сиротских' parent_id: {len(orphan_parents)}\")\n",
    "\n",
    "# Проверка уникальности category_id\n",
    "cat_id_duplicates = category_tree.duplicated(subset=['category_id']).sum()\n",
    "print(f\"   - category_tree дубликаты category_id: {cat_id_duplicates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a67908",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ДАННЫЕ ПОДГОТОВЛЕНЫ ДАЛЬНЕЙШЕМУ АНАЛИЗУ\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"events: {len(events):,} строк (удалено {initial_events_size - len(events):,} дубликатов)\")\n",
    "print(f\"category_tree: {len(category_tree):,} строк\")\n",
    "print(f\"item_properties: {len(item_properties):,} строк\")\n",
    "print(f\"Столбцы переименованы в PEP8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b609a406",
   "metadata": {},
   "source": [
    "ЭТАП 2: EDA  \n",
    "\n",
    "`category_tree.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем папку для графиков\n",
    "os.makedirs('mlflow_server/eda_plots', exist_ok=True)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"АНАЛИЗ category_tree\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Базовая информация\n",
    "print(\"1. БАЗОВАЯ ИНФОРМАЦИЯ:\")\n",
    "print(f\"   - Всего записей: {len(category_tree):,}\")\n",
    "print(f\"   - Уникальных категорий: {category_tree['category_id'].nunique():,}\")\n",
    "print(f\"   - Пропуски в parent_id: {category_tree['parent_id'].isna().sum():,}\")\n",
    "\n",
    "# 2. Анализ структуры дерева\n",
    "print(\"\\n2. СТРУКТУРА ДЕРЕВА КАТЕГОРИЙ:\")\n",
    "\n",
    "# Корневые категории (без родителя)\n",
    "root_categories = category_tree[category_tree['parent_id'].isna()]\n",
    "print(f\"   - Корневых категорий (без родителя): {len(root_categories):,}\")\n",
    "\n",
    "# Категории, которые являются родителями (имеют дочерние)\n",
    "parent_categories = category_tree[category_tree['category_id'].isin(category_tree['parent_id'])]\n",
    "print(f\"   - Категорий, имеющих дочерние: {parent_categories['category_id'].nunique():,}\")\n",
    "\n",
    "# Конечные категории (не являются родителями)\n",
    "leaf_categories = category_tree[~category_tree['category_id'].isin(category_tree['parent_id'])]\n",
    "print(f\"   - Конечных категорий (без дочерних): {leaf_categories['category_id'].nunique():,}\")\n",
    "\n",
    "# 3. Анализ распределения количества дочерних категорий\n",
    "print(\"\\n3. РАСПРЕДЕЛЕНИЕ ДОЧЕРНИХ КАТЕГОРИЙ:\")\n",
    "child_counts = category_tree['parent_id'].value_counts()\n",
    "print(f\"   - Максимум дочерних категорий у одного родителя: {child_counts.max()}\")\n",
    "print(f\"   - Среднее количество дочерних категорий: {child_counts.mean():.1f}\")\n",
    "print(f\"   - Медиана количества дочерних категорий: {child_counts.median():.1f}\")\n",
    "\n",
    "# 4. Визуализация с сохранением графиков\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# График 1: Типы категорий\n",
    "plt.subplot(1, 3, 1)\n",
    "category_types = [len(leaf_categories), len(parent_categories), len(root_categories)]\n",
    "labels = ['Конечные', 'Родительские', 'Корневые']\n",
    "plt.bar(labels, category_types, color=['lightgreen', 'lightcoral', 'gold'])\n",
    "plt.title('Распределение по типам категорий')\n",
    "plt.ylabel('Количество категорий')\n",
    "for i, v in enumerate(category_types):\n",
    "    plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "# График 2: Top-15 родительских категорий по количеству дочерних\n",
    "plt.subplot(1, 3, 2)\n",
    "top_parents = child_counts.head(15)\n",
    "plt.bar([str(int(x)) for x in top_parents.index], top_parents.values, color='skyblue')\n",
    "plt.title('Top-15 родительских категорий')\n",
    "plt.xlabel('ID категории')\n",
    "plt.ylabel('Количество дочерних')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# График 3: Распределение количества дочерних категорий\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(child_counts.values, bins=30, color='orange', edgecolor='black')\n",
    "plt.title('Распределение количества дочерних категорий')\n",
    "plt.xlabel('Количество дочерних категорий')\n",
    "plt.ylabel('Частота')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('mlflow_server/eda_plots/category_tree_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 5. Дополнительные графики\n",
    "# График 4: Распределение категорий (логарифмическая шкала)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(child_counts.values, bins=50, color='purple', edgecolor='black', log=True)\n",
    "plt.title('Распределение количества дочерних категорий (логарифмическая шкала)')\n",
    "plt.xlabel('Количество дочерних категорий')\n",
    "plt.ylabel('Частота (log scale)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(f'{ASSETS_DIR}/category_tree_distribution_log.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 6. Детальный анализ топ-5 родительских категорий\n",
    "print(\"\\n4. ДЕТАЛЬНЫЙ АНАЛИЗ TOP-5 РОДИТЕЛЬСКИХ КАТЕГОРИЙ:\")\n",
    "top_5_parents = child_counts.head(5)\n",
    "for parent_id, child_count in top_5_parents.items():\n",
    "    if pd.isna(parent_id):\n",
    "        continue\n",
    "    print(f\"   - Категория {int(parent_id)}: {child_count} дочерних категорий\")\n",
    "\n",
    "# 7. Проверка целостности данных\n",
    "print(\"\\n5. ПРОВЕРКА ЦЕЛОСТНОСТИ ДАННЫХ:\")\n",
    "# Категории, которые есть в parent_id, но нет в category_id\n",
    "orphan_parents = set(category_tree['parent_id'].dropna()) - set(category_tree['category_id'])\n",
    "print(f\"   - 'Сиротских' parent_id (нет в category_id): {len(orphan_parents)}\")\n",
    "\n",
    "# 8. Статистика\n",
    "print(\"\\n6. СТАТИСТИКА:\")\n",
    "print(category_tree.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a73b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ВЫВОДЫ ПО CATEGORY_TREE:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n СТРУКТУРА ДАННЫХ:\")\n",
    "print(f\"- Всего {len(category_tree):,} категорий в иерархии\")\n",
    "print(f\"- {len(root_categories):,} корневых категорий (основные разделы магазина)\")\n",
    "print(f\"- {len(parent_categories):,} родительских категорий (средний уровень вложенности)\") \n",
    "print(f\"- {len(leaf_categories):,} конечных категорий (конкретные товарные группы)\")\n",
    "\n",
    "print(\"\\n СТАТИСТИКА РАСПРЕДЕЛЕНИЯ:\")\n",
    "print(f\"- Максимальная ширина дерева: {child_counts.max()} дочерних у одного родителя\")\n",
    "print(f\"- Среднее количество дочерних: {child_counts.mean():.1f} на родителя\")\n",
    "print(f\"- Медианное количество: {child_counts.median():.1f} дочерних на родителя\")\n",
    "print(f\"- Распределение имеет 'длинный хвост' - большинство категорий имеют мало дочерних\")\n",
    "\n",
    "print(\"\\n КАЧЕСТВО ДАННЫХ:\")\n",
    "print(f\"- Нет дубликатов - данные чистые\")\n",
    "print(f\"- Нет сиротских категорий - все ссылки целостные\")\n",
    "print(f\"- {category_tree['parent_id'].isna().sum()} пропусков (корневые категории - ожидаемо)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb54e929",
   "metadata": {},
   "source": [
    "`events.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c228e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем папку для графиков (если еще не создана)\n",
    "os.makedirs('mlflow_server/eda_plots', exist_ok=True)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ГЛУБОКИЙ АНАЛИЗ EVENTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Базовая информация\n",
    "print(\"1. БАЗОВАЯ ИНФОРМАЦИЯ:\")\n",
    "print(f\"   - Всего событий: {len(events):,}\")\n",
    "print(f\"   - Уникальных пользователей: {events['visitor_id'].nunique():,}\")\n",
    "print(f\"   - Уникальных товаров: {events['item_id'].nunique():,}\")\n",
    "print(f\"   - Период данных: от {pd.to_datetime(events['timestamp'].min(), unit='ms')} до {pd.to_datetime(events['timestamp'].max(), unit='ms')}\")\n",
    "\n",
    "# 2. Анализ типов событий\n",
    "print(\"\\n2. РАСПРЕДЕЛЕНИЕ ТИПОВ СОБЫТИЙ:\")\n",
    "event_counts = events['event'].value_counts()\n",
    "event_percentages = (event_counts / len(events)) * 100\n",
    "\n",
    "for event, count in event_counts.items():\n",
    "    percentage = event_percentages[event]\n",
    "    print(f\"   - {event}: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "# 3. Анализ транзакций\n",
    "print(\"\\n3. АНАЛИЗ ТРАНЗАКЦИЙ:\")\n",
    "transactions = events[events['transaction_id'].notna()]\n",
    "print(f\"   - Всего транзакций (покупок): {transactions['transaction_id'].nunique():,}\")\n",
    "print(f\"   - Уникальных товаров в покупках: {transactions['item_id'].nunique():,}\")\n",
    "print(f\"   - Уникальных пользователей, совершивших покупки: {transactions['visitor_id'].nunique():,}\")\n",
    "\n",
    "# 4. НОВЫЕ МЕТРИКИ\n",
    "print(\"\\n4. КЛЮЧЕВЫЕ БИЗНЕС-МЕТРИКИ:\")\n",
    "\n",
    "# Уникальные пользователи\n",
    "print(f\"   - Уникальных пользователей: {events['visitor_id'].nunique():,}\")\n",
    "\n",
    "# Расчет пользователей, добавивших в корзину\n",
    "addtocart_events = events[events['event'] == 'addtocart']\n",
    "addtocart_users = addtocart_events['visitor_id'].nunique()\n",
    "\n",
    "# Конверсия пользователей в покупки\n",
    "conversion_rate = (transactions['visitor_id'].nunique() / events['visitor_id'].nunique()) * 100\n",
    "print(f\"   - Конверсия пользователей в покупки: {conversion_rate:.2f}%\")\n",
    "\n",
    "# Конверсия пользователей в корзину\n",
    "addtocart_conversion = (addtocart_users / events['visitor_id'].nunique()) * 100\n",
    "print(f\"   - Конверсия пользователей в корзину: {addtocart_conversion:.2f}%\")\n",
    "\n",
    "# Конверсия из корзины в покупку\n",
    "cart_to_purchase_rate = (transactions['visitor_id'].nunique() / addtocart_users) * 100\n",
    "print(f\"   - Конверсия из корзины в покупку: {cart_to_purchase_rate:.2f}%\")\n",
    "\n",
    "# Расчет статистики по пользователям\n",
    "user_stats = events.groupby('visitor_id').agg({\n",
    "    'event': 'count',\n",
    "    'item_id': 'nunique'\n",
    "}).round(2)\n",
    "user_stats.columns = ['total_events', 'unique_items']\n",
    "\n",
    "# Средние события на пользователя\n",
    "avg_events_per_user = user_stats['total_events'].mean()\n",
    "print(f\"   - Среднее событий на пользователя: {avg_events_per_user:.1f}\")\n",
    "\n",
    "# Среднее уникальных товаров на пользователя  \n",
    "avg_items_per_user = user_stats['unique_items'].mean()\n",
    "print(f\"   - Среднее уникальных товаров на пользователя: {avg_items_per_user:.1f}\")\n",
    "\n",
    "# 5. Преобразование временных меток для анализа\n",
    "events['datetime'] = pd.to_datetime(events['timestamp'], unit='ms')\n",
    "events['date'] = events['datetime'].dt.date\n",
    "events['hour'] = events['datetime'].dt.hour\n",
    "events['day_of_week'] = events['datetime'].dt.day_name()\n",
    "events['month'] = events['datetime'].dt.month\n",
    "events['year_month'] = events['datetime'].dt.to_period('M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36caf8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Анализ по месяцам\n",
    "print(\"\\n5. АНАЛИЗ ПО МЕСЯЦАМ:\")\n",
    "monthly_stats = events.groupby('year_month').agg({\n",
    "    'visitor_id': 'nunique',\n",
    "    'item_id': 'nunique',\n",
    "    'event': 'count'\n",
    "}).round(2)\n",
    "\n",
    "monthly_stats.columns = ['unique_visitors', 'unique_items', 'total_events']\n",
    "print(\"   Месяц | Уникальные посетители | Уникальные товары | Всего событий\")\n",
    "print(\"   \" + \"-\" * 70)\n",
    "\n",
    "for month, stats in monthly_stats.iterrows():\n",
    "    print(f\"   {month} | {stats['unique_visitors']:>18,} | {stats['unique_items']:>16,} | {stats['total_events']:>12,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb351ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Визуализация с сохранением графиков - ОПТИМИЗИРОВАННАЯ ВЕРСИЯ\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "# ПЕРВАЯ СТРОКА: Основные метрики\n",
    "# График 1: Распределение типов событий\n",
    "plt.subplot(3, 4, 1)\n",
    "colors = ['lightblue', 'lightcoral', 'lightgreen']\n",
    "\n",
    "event_names_ru = {\n",
    "    'view': 'Просмотр',\n",
    "    'addtocart': 'В корзину', \n",
    "    'transaction': 'Покупка'\n",
    "}\n",
    "\n",
    "events_ru = [event_names_ru[event] for event in event_counts.index]\n",
    "counts_ru = event_counts.values\n",
    "\n",
    "bars = plt.bar(events_ru, counts_ru, color=colors, alpha=0.7)\n",
    "plt.title('Распределение типов событий', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Количество событий', fontsize=10)\n",
    "plt.xlabel('Тип события', fontsize=10)\n",
    "plt.xticks(rotation=45, fontsize=9)\n",
    "\n",
    "# Увеличиваем верхний предел оси Y на 10%\n",
    "plt.ylim(0, max(counts_ru) * 1.1)\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for bar, count, percentage in zip(bars, counts_ru, event_percentages.values):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "             f'{count:,}\\n({percentage:.1f}%)', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# График 2: Конверсия по воронке\n",
    "plt.subplot(3, 4, 2)\n",
    "funnel_data = [\n",
    "    events['visitor_id'].nunique(),\n",
    "    addtocart_users,\n",
    "    transactions['visitor_id'].nunique()\n",
    "]\n",
    "funnel_labels = ['Всего\\nпосетителей', 'Добавили\\nв корзину', 'Совершили\\nпокупку']\n",
    "funnel_colors = ['lightblue', 'lightcoral', 'lightgreen']\n",
    "\n",
    "bars_funnel = plt.bar(funnel_labels, funnel_data, color=funnel_colors, alpha=0.7)\n",
    "plt.title('Воронка конверсии', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Количество пользователей', fontsize=10)\n",
    "\n",
    "# Добавляем значения и проценты на воронку\n",
    "for i, (bar, count) in enumerate(zip(bars_funnel, funnel_data)):\n",
    "    height = bar.get_height()\n",
    "    if i > 0:\n",
    "        prev_count = funnel_data[i-1]\n",
    "        conversion = (count / prev_count) * 100\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                f'{count:,}\\n({conversion:.1f}%)', ha='center', va='bottom', fontsize=8)\n",
    "    else:\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                f'{count:,}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# График 3: Активность по месяцам\n",
    "plt.subplot(3, 4, 3)\n",
    "monthly_activity = events.groupby('year_month').size()\n",
    "monthly_activity.plot(kind='bar', color='teal', alpha=0.7)\n",
    "plt.title('Активность по месяцам', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Количество событий', fontsize=10)\n",
    "plt.xlabel('Месяц', fontsize=10)\n",
    "plt.xticks(rotation=45, fontsize=8)\n",
    "\n",
    "# График 4: Уникальные посетители по месяцам\n",
    "plt.subplot(3, 4, 4)\n",
    "monthly_visitors = events.groupby('year_month')['visitor_id'].nunique()\n",
    "monthly_visitors.plot(kind='bar', color='orange', alpha=0.7)\n",
    "plt.title('Уникальные посетители по месяцам', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Количество посетителей', fontsize=10)\n",
    "plt.xlabel('Месяц', fontsize=10)\n",
    "plt.xticks(rotation=45, fontsize=8)\n",
    "\n",
    "# ВТОРАЯ СТРОКА: Временные паттерны\n",
    "# График 5: Активность по дням недели\n",
    "plt.subplot(3, 4, 5)\n",
    "weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "weekday_activity = events.groupby('day_of_week').size().reindex(weekday_order)\n",
    "weekday_activity.plot(kind='bar', color='purple', alpha=0.7)\n",
    "plt.title('Активность по дням недели', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Количество событий', fontsize=10)\n",
    "plt.xlabel('День недели', fontsize=10)\n",
    "plt.xticks(rotation=45, fontsize=9)\n",
    "\n",
    "# График 6: Активность по часам\n",
    "plt.subplot(3, 4, 6)\n",
    "hourly_activity = events.groupby('hour').size()\n",
    "hourly_activity.plot(kind='bar', color='green', alpha=0.7)\n",
    "plt.title('Активность по часам суток', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Количество событий', fontsize=10)\n",
    "plt.xlabel('Час дня', fontsize=10)\n",
    "plt.xticks(fontsize=9)\n",
    "\n",
    "# График 7: Уникальные товары по месяцам\n",
    "plt.subplot(3, 4, 7)\n",
    "monthly_items = events.groupby('year_month')['item_id'].nunique()\n",
    "monthly_items.plot(kind='bar', color='blue', alpha=0.7)\n",
    "plt.title('Уникальные товары по месяцам', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Количество товаров', fontsize=10)\n",
    "plt.xlabel('Месяц', fontsize=10)\n",
    "plt.xticks(rotation=45, fontsize=8)\n",
    "\n",
    "# График 8: Пустой слот для баланса или можно добавить другой график\n",
    "plt.subplot(3, 4, 8)\n",
    "# Можно добавить дополнительный график или оставить пустым для баланса\n",
    "plt.text(0.5, 0.5, 'Дополнительная\\nаналитика', ha='center', va='center', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "# ТРЕТЬЯ СТРОКА: Распределения\n",
    "# График 9: Распределение событий на пользователя\n",
    "plt.subplot(3, 4, 9)\n",
    "user_event_counts = events.groupby('visitor_id').size()\n",
    "plt.hist(user_event_counts.values, bins=50, color='red', alpha=0.7, log=True)\n",
    "plt.title('Событий на пользователя\\n(логарифмическая шкала)', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Количество событий на пользователя', fontsize=10)\n",
    "plt.ylabel('Частота (log scale)', fontsize=10)\n",
    "\n",
    "# График 10: Распределение популярности товаров\n",
    "plt.subplot(3, 4, 10)\n",
    "item_popularity = events.groupby('item_id').size()\n",
    "plt.hist(item_popularity.values, bins=50, color='brown', alpha=0.7, log=True)\n",
    "plt.title('Популярность товаров\\n(логарифмическая шкала)', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Количество событий на товар', fontsize=10)\n",
    "plt.ylabel('Частота (log scale)', fontsize=10)\n",
    "\n",
    "# График 11: Распределение уникальных товаров на пользователя\n",
    "plt.subplot(3, 4, 11)\n",
    "user_stats = events.groupby('visitor_id').agg({'item_id': 'nunique'})\n",
    "plt.hist(user_stats['item_id'].values, bins=30, color='darkgreen', alpha=0.7, log=True)\n",
    "plt.title('Уникальных товаров на пользователя\\n(логарифмическая шкала)', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Уникальных товаров на пользователя', fontsize=10)\n",
    "plt.ylabel('Частота (log scale)', fontsize=10)\n",
    "\n",
    "# График 12: Соотношение новых и вернувшихся пользователей (упрощенная версия)\n",
    "plt.subplot(3, 4, 12)\n",
    "user_first_visit = events.groupby('visitor_id')['datetime'].min()\n",
    "user_visit_count = events.groupby('visitor_id').size()\n",
    "\n",
    "single_visit_users = len(user_visit_count[user_visit_count == 1])\n",
    "multiple_visit_users = len(user_visit_count[user_visit_count > 1])\n",
    "\n",
    "returning_data = [single_visit_users, multiple_visit_users]\n",
    "returning_labels = ['Однократные\\nпосетители', 'Многократные\\nпосетители']\n",
    "returning_colors = ['lightgray', 'darkorange']\n",
    "\n",
    "plt.pie(returning_data, labels=returning_labels, colors=returning_colors, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Однократные vs Многократные\\nпосетители', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{ASSETS_DIR}/events_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 8. Детальный анализ пользователей\n",
    "print(\"\\n6. 👥 ДЕТАЛЬНЫЙ АНАЛИЗ ПОЛЬЗОВАТЕЛЕЙ:\")\n",
    "user_stats = events.groupby('visitor_id').agg({\n",
    "    'event': 'count',\n",
    "    'item_id': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "user_stats.columns = ['total_events', 'unique_items']\n",
    "print(f\"   - Среднее событий на пользователя: {user_stats['total_events'].mean():.1f}\")\n",
    "print(f\"   - Медиана событий на пользователя: {user_stats['total_events'].median():.1f}\")\n",
    "print(f\"   - Среднее уникальных товаров на пользователя: {user_stats['unique_items'].mean():.1f}\")\n",
    "print(f\"   - Максимум событий у одного пользователя: {user_stats['total_events'].max()}\")\n",
    "\n",
    "# 9. Топ-5 самых активных пользователей\n",
    "print(\"\\n7. ТОП-5 САМЫХ АКТИВНЫХ ПОЛЬЗОВАТЕЛЕЙ:\")\n",
    "top_users = user_stats.nlargest(5, 'total_events')\n",
    "for i, (user_id, stats) in enumerate(top_users.iterrows(), 1):\n",
    "    print(f\"   {i}. User {user_id}: {stats['total_events']} событий, {stats['unique_items']} товаров\")\n",
    "\n",
    "# 10. Топ-5 самых популярных товаров\n",
    "print(\"\\n8. ТОП-5 САМЫХ ПОПУЛЯРНЫХ ТОВАРОВ:\")\n",
    "top_items = item_popularity.nlargest(5)\n",
    "for i, (item_id, count) in enumerate(top_items.items(), 1):\n",
    "    print(f\"   {i}. Item {item_id}: {count} событий\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ИТОГОВЫЕ ВЫВОДЫ ПО EVENTS:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"ОСНОВНЫЕ МЕТРИКИ:\")\n",
    "print(f\"- Всего {len(events):,} событий от {events['visitor_id'].nunique():,} пользователей\")\n",
    "print(f\"- {events['item_id'].nunique():,} уникальных товаров\")\n",
    "print(f\"- Период данных: {(events['datetime'].max() - events['datetime'].min()).days} дней (май-сентябрь 2015)\")\n",
    "\n",
    "print(\"\\n РАСПРЕДЕЛЕНИЕ СОБЫТИЙ:\")\n",
    "print(f\"- Доминируют просмотры: {event_percentages.iloc[0]:.1f}% всех событий\")\n",
    "print(f\"- Низкая активность: всего {event_percentages.iloc[1]:.1f}% добавлений в корзину\")\n",
    "print(f\"- Минимальные покупки: {event_percentages.iloc[2]:.1f}% транзакций\")\n",
    "\n",
    "print(\"\\n БИЗНЕС-МЕТРИКИ И КОНВЕРСИЯ:\")\n",
    "print(f\"- ОЧЕНЬ НИЗКАЯ конверсия: всего {conversion_rate:.2f}% пользователей совершают покупки\")\n",
    "print(f\"- Мало вовлеченных: {addtocart_conversion:.2f}% пользователей добавляют в корзину\")\n",
    "print(f\"- ХОРОШАЯ конверсия из корзины: {cart_to_purchase_rate:.2f}% (каждый 3-й покупает)\")\n",
    "\n",
    "print(\"\\n ПОВЕДЕНИЕ ПОЛЬЗОВАТЕЛЕЙ:\")\n",
    "print(f\"- Средняя активность: {user_stats['total_events'].mean():.1f} событий на пользователя\")\n",
    "print(f\"- Низкое взаимодействие: {user_stats['unique_items'].mean():.1f} уникальных товаров на пользователя\")\n",
    "print(f\"- Сильный разброс: от 1 до {user_stats['total_events'].max()} событий на пользователя\")\n",
    "\n",
    "print(\"\\n СЕЗОННОСТЬ И ТРЕНДЫ:\")\n",
    "print(f\"- Пик активности: июль 2015 ({monthly_stats.loc['2015-07', 'total_events']:,} событий)\")\n",
    "print(f\"- Спад к сентябрю: {monthly_stats.loc['2015-09', 'total_events']:,} событий\")\n",
    "print(f\"- Стабильный охват: 300K+ пользователей ежемесячно\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf209bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n КЛЮЧЕВЫЕ ИНСАЙТЫ ДЛЯ РЕКОМЕНДАТЕЛЬНОЙ СИСТЕМЫ:\")\n",
    "print(\"1. Фокус на ВОВЛЕЧЕНИЕ - нужно увеличивать переход от просмотров к действиям\")\n",
    "print(\"2. Улучшать конверсию в корзину - основной 'бутылочный горлышко'\")\n",
    "print(\"3. Персонализировать для 'холодных' пользователей - 97% только просматривают\")\n",
    "print(\"4. Использовать топ-товары (187946, 461686) как якорь для рекомендаций\")\n",
    "print(\"5. Учитывать временные паттерны - пики активности по часам/дням\")\n",
    "\n",
    "print(f\"\\n ГРАФИКИ СОХРАНЕНЫ: 'mlflow_server/eda_plots/events_analysis.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e03d37",
   "metadata": {},
   "source": [
    "все наблюдаемые выбросы оставляем:\n",
    "\n",
    "1. Пользователи-выбросы:  \n",
    "   - Это \"супер-пользователи\" - их поведение ценно для обучения  \n",
    "   - Показывают максимальное вовлечение  \n",
    "   - Помогают понять \"идеальный\" путь покупки  \n",
    "2. Товары-выбросы:  \n",
    "   - Это хиты - важно понимать что популярно  \n",
    "   - Могут быть якорем для рекомендаций\n",
    "3. Временные выбросы:    \n",
    "   - Пики активности в определенные часы/дни  \n",
    "   - Это паттерны, а не шум"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a605ffc",
   "metadata": {},
   "source": [
    "`item_properties.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c7054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем папку для графиков\n",
    "os.makedirs('mlflow_server/eda_plots', exist_ok=True)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\" АНАЛИЗ item_properties\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Базовая информация\n",
    "print(\"1. БАЗОВАЯ ИНФОРМАЦИЯ:\")\n",
    "print(f\"   - Всего записей свойств: {len(item_properties):,}\")\n",
    "print(f\"   - Уникальных товаров: {item_properties['item_id'].nunique():,}\")\n",
    "print(f\"   - Уникальных свойств: {item_properties['property'].nunique():,}\")\n",
    "print(f\"   - Период обновления свойств: от {pd.to_datetime(item_properties['timestamp'].min(), unit='ms')} до {pd.to_datetime(item_properties['timestamp'].max(), unit='ms')}\")\n",
    "\n",
    "# 2. Анализ пропусков\n",
    "print(\"\\n2. ПРОВЕРКА КАЧЕСТВА ДАННЫХ:\")\n",
    "print(f\"   - Пропуски: {item_properties.isnull().sum().sum()}\")\n",
    "print(f\"   - Дубликаты: {item_properties.duplicated().sum()}\")\n",
    "\n",
    "# 3. Анализ самых частых свойств\n",
    "print(\"\\n3. ТОП-20 САМЫХ ЧАСТЫХ СВОЙСТВ ТОВАРОВ:\")\n",
    "top_properties = item_properties['property'].value_counts().head(20)\n",
    "for prop, count in top_properties.items():\n",
    "    percentage = (count / len(item_properties)) * 100\n",
    "    print(f\"   - {prop}: {count:,} ({percentage:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16c0d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Анализ товаров с наибольшим количеством свойств\n",
    "print(\"\\n4. АНАЛИЗ ТОВАРОВ ПО КОЛИЧЕСТВУ СВОЙСТВ:\")\n",
    "props_per_item = item_properties.groupby('item_id').size()\n",
    "print(f\"   - Максимум свойств у одного товара: {props_per_item.max()}\")\n",
    "print(f\"   - Среднее свойств на товар: {props_per_item.mean():.1f}\")\n",
    "print(f\"   - Медиана свойств на товар: {props_per_item.median():.1f}\")\n",
    "\n",
    "# 5. Преобразование временных меток\n",
    "item_properties['datetime'] = pd.to_datetime(item_properties['timestamp'], unit='ms')\n",
    "item_properties['date'] = item_properties['datetime'].dt.date\n",
    "item_properties['year_month'] = item_properties['datetime'].dt.to_period('M')\n",
    "\n",
    "# 6. Анализ по месяцам\n",
    "print(\"\\n5. ОБНОВЛЕНИЕ СВОЙСТВ ПО МЕСЯЦАМ:\")\n",
    "monthly_updates = item_properties.groupby('year_month').size()\n",
    "print(\"   Месяц | Обновлений свойств\")\n",
    "print(\"   \" + \"-\" * 30)\n",
    "for month, count in monthly_updates.items():\n",
    "    print(f\"   {month} | {count:>15,}\")\n",
    "\n",
    "# 7. Анализ значений для ключевых свойств\n",
    "print(\"\\n6. АНАЛИЗ ЗНАЧЕНИЙ КЛЮЧЕВЫХ СВОЙСТВ:\")\n",
    "\n",
    "# Смотрим на категории (самое частое свойство)\n",
    "if 'categoryid' in item_properties['property'].values:\n",
    "    category_values = item_properties[item_properties['property'] == 'categoryid']['value']\n",
    "    print(f\"   - Уникальных категорий в свойствах: {category_values.nunique()}\")\n",
    "    print(f\"   - Примеры категорий: {category_values.value_counts().head(5).to_dict()}\")\n",
    "\n",
    "# Анализ availability (доступности товаров)\n",
    "if 'available' in item_properties['property'].values:\n",
    "    available_values = item_properties[item_properties['property'] == 'available']['value']\n",
    "    print(f\"   - Статусы доступности: {available_values.value_counts().to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8. Визуализация\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# График 1: Топ-15 свойств товаров\n",
    "plt.subplot(2, 3, 1)\n",
    "top_15_props = item_properties['property'].value_counts().head(15)\n",
    "plt.barh(top_15_props.index, top_15_props.values, color='lightblue')\n",
    "plt.title('Топ-15 свойств товаров')\n",
    "plt.xlabel('Количество записей')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# График 2: Распределение количества свойств на товар\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.hist(props_per_item.values, bins=50, color='lightcoral', alpha=0.7, log=True)\n",
    "plt.title('Распределение свойств на товар\\n(логарифмическая шкала)')\n",
    "plt.xlabel('Количество свойств на товар')\n",
    "plt.ylabel('Частота (log scale)')\n",
    "\n",
    "# График 3: Обновление свойств по месяцам\n",
    "plt.subplot(2, 3, 3)\n",
    "monthly_updates.plot(kind='bar', color='lightgreen', alpha=0.7)\n",
    "plt.title('Обновление свойств по месяцам')\n",
    "plt.xlabel('Месяц')\n",
    "plt.ylabel('Количество обновлений')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# График 4: Топ-10 товаров по количеству свойств\n",
    "plt.subplot(2, 3, 4)\n",
    "top_items_props = props_per_item.nlargest(10)\n",
    "plt.bar([str(x) for x in top_items_props.index], top_items_props.values, color='orange')\n",
    "plt.title('Топ-10 товаров по количеству свойств')\n",
    "plt.xlabel('ID товара')\n",
    "plt.ylabel('Количество свойств')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# График 5: Распределение длины значений свойств\n",
    "plt.subplot(2, 3, 5)\n",
    "value_lengths = item_properties['value'].str.len()\n",
    "plt.hist(value_lengths, bins=50, color='purple', alpha=0.7, log=True)\n",
    "plt.title('Распределение длины значений свойств\\n(логарифмическая шкала)')\n",
    "plt.xlabel('Длина значения свойства')\n",
    "plt.ylabel('Частота (log scale)')\n",
    "\n",
    "# График 6: Активность обновления свойств по дням\n",
    "plt.subplot(2, 3, 6)\n",
    "daily_updates = item_properties.groupby('date').size()\n",
    "daily_updates.plot(color='teal', alpha=0.7)\n",
    "plt.title('Активность обновления свойств по дням')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Количество обновлений')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{ASSETS_DIR}/item_properties_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9. Детальный анализ\n",
    "print(\"\\n7. ДЕТАЛЬНЫЙ АНАЛИЗ:\")\n",
    "print(f\"   - Топ-5 товаров с наибольшим количеством свойств:\")\n",
    "top_5_items = props_per_item.nlargest(5)\n",
    "for i, (item_id, count) in enumerate(top_5_items.items(), 1):\n",
    "    print(f\"     {i}. Item {item_id}: {count} свойств\")\n",
    "\n",
    "print(f\"\\n   - Топ-5 самых редких свойств:\")\n",
    "rare_props = item_properties['property'].value_counts().tail(5)\n",
    "for prop, count in rare_props.items():\n",
    "    print(f\"     - {prop}: {count} записей\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ВЫВОДЫ ПО items_properties:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"- Всего {len(item_properties):,} записей свойств\")\n",
    "print(f\"- {item_properties['item_id'].nunique():,} товаров имеют свойства\") \n",
    "print(f\"- {item_properties['property'].nunique():,} уникальных свойств\")\n",
    "print(f\"- Качество данных: отличное (0 пропусков)\")\n",
    "print(f\"- Графики сохранены в 'eda_plots/item_properties_analysis.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d36a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ИТОГОВЫЕ ВЫВОДЫ ПО ITEM_PROPERTIES:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\" ОСНОВНЫЕ МЕТРИКИ:\")\n",
    "print(f\" Огромный объем данных: {len(item_properties):,} записей свойств\")\n",
    "print(f\" Широкий ассортимент: {item_properties['item_id'].nunique():,} товаров с характеристиками\")\n",
    "print(f\" Богатая атрибутика: {item_properties['property'].nunique():,} уникальных свойств\")\n",
    "\n",
    "print(\"\\n СТРУКТУРА СВОЙСТВ:\")\n",
    "print(f\" Доминируют числовые свойства: '888' (14.8%), '790' (8.8%)\")\n",
    "print(f\" Важные категориальные: 'categoryid' (3.9%), 'available' (7.4%)\")\n",
    "print(f\" Сбалансированное распределение: 48.6 свойств на товар в среднем\")\n",
    "\n",
    "print(\"\\n ДИНАМИКА ОБНОВЛЕНИЙ:\")\n",
    "print(f\" Пик активности: май 2015 ({monthly_updates.loc['2015-05']:,} обновлений)\")\n",
    "print(f\" Постепенное снижение: до {monthly_updates.loc['2015-09']:,} в сентябре\")\n",
    "print(f\" Постоянное обновление: свойства меняются регулярно\")\n",
    "\n",
    "print(\"\\n КЛЮЧЕВЫЕ ИНСАЙТЫ:\")\n",
    "print(f\" Категории: 1,242 уникальных категорий (больше чем в category_tree)\")\n",
    "print(f\" Доступность: {available_values.value_counts().to_dict()} (64% товаров доступны)\")\n",
    "print(f\" Детализация: товары имеют от 1 до 468 свойств\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e04541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075fca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40139fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000c058",
   "metadata": {},
   "source": [
    " ЭТАП 3: Объеденение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adb5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ОБЪЕДИНЕНИЕ ДАННЫХ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Анализ пересечений между таблицами\n",
    "print(\"1. АНАЛИЗ ПЕРЕСЕЧЕНИЙ МЕЖДУ ТАБЛИЦАМИ\")\n",
    "\n",
    "# Товары в events vs item_properties\n",
    "events_items = set(events['item_id'].unique())\n",
    "props_items = set(item_properties['item_id'].unique())\n",
    "\n",
    "print(f\"- Уникальных товаров в events: {len(events_items):,}\")\n",
    "print(f\"   - Уникальных товаров в item_properties: {len(props_items):,}\")\n",
    "print(f\"   - Пересечение: {len(events_items & props_items):,} товаров\")\n",
    "\n",
    "# Категории в item_properties vs category_tree\n",
    "props_categories = set(item_properties[item_properties['property'] == 'categoryid']['value'].astype(int))\n",
    "tree_categories = set(category_tree['category_id'].unique())\n",
    "\n",
    "print(f\"   - Категорий в свойствах: {len(props_categories):,}\")\n",
    "print(f\"   - Категорий в category_tree: {len(tree_categories):,}\")\n",
    "print(f\"   - Пересечение: {len(props_categories & tree_categories):,} категорий\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cfc317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Получаем актуальные категории товаров\n",
    "print(\"\\n2. ПОЛУЧАЕМ АКТУАЛЬНЫЕ КАТЕГОРИИ ТОВАРОВ\")\n",
    "\n",
    "latest_categories = (\n",
    "    item_properties[item_properties['property'] == 'categoryid']\n",
    "    .sort_values('timestamp', ascending=False)\n",
    "    .groupby('item_id')\n",
    "    .first()\n",
    "    .reset_index()[['item_id', 'value']]\n",
    "    .rename(columns={'value': 'category_id'})\n",
    ")\n",
    "latest_categories['category_id'] = latest_categories['category_id'].astype(int)\n",
    "\n",
    "print(f\"   - Товаров с категориями: {len(latest_categories):,}\")\n",
    "\n",
    "# 3. Объединяем events с категориями\n",
    "print(\"\\n3. ОБЪЕДИНЯЕМ EVENTS С КАТЕГОРИЯМИ\")\n",
    "\n",
    "events_with_cats = events.merge(latest_categories, on='item_id', how='left')\n",
    "print(f\"   - Событий с категориями: {events_with_cats['category_id'].notna().sum():,}\")\n",
    "\n",
    "# 4. Добавляем иерархию категорий\n",
    "print(\"\\n4. ДОБАВЛЯЕМ ИЕРАРХИЮ КАТЕГОРИЙ\")\n",
    "\n",
    "final_data = events_with_cats.merge(category_tree, on='category_id', how='left')\n",
    "print(f\"   - Событий с полной иерархией: {final_data['parent_id'].notna().sum():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eaf7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Добавляем целевые переменные\n",
    "print(\"\\n5. ДОБАВЛЯЕМ ЦЕЛЕВЫЕ ПЕРЕМЕННЫЕ\")\n",
    "\n",
    "final_data['target_addtocart'] = (final_data['event'] == 'addtocart').astype(int)\n",
    "final_data['was_purchased'] = (final_data['event'] == 'transaction').astype(int)\n",
    "\n",
    "print(f\"   - Добавлений в корзину: {final_data['target_addtocart'].sum():,}\")\n",
    "print(f\"   - Покупок: {final_data['was_purchased'].sum():,}\")\n",
    "print(f\"   - Доля добавлений в корзину: {final_data['target_addtocart'].mean()*100:.2f}%\")\n",
    "print(f\"   - Доля покупок: {final_data['was_purchased'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29937c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Финальная проверка\n",
    "print(\"\\n6. ФИНАЛЬНАЯ ПРОВЕРКА ДАННЫХ\")\n",
    "\n",
    "print(f\"   - Итоговый размер: {len(final_data):,} строк\")\n",
    "print(f\"   - Покрытие категориями: {final_data['category_id'].notna().sum()/len(final_data)*100:.1f}%\")\n",
    "print(f\"   - Сохранена структура: {len(final_data) == len(events)}\")\n",
    "print(f\"   - Добавленные фичи: target_addtocart, was_purchased\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ОБЪЕДИНЕНИЕ ДАННЫХ ЗАВЕРШЕНО!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"РЕЗУЛЬТАТ:\")\n",
    "print(f\"- {len(final_data):,} событий\")\n",
    "print(f\"- {final_data['category_id'].notna().sum():,} событий с категориями\")\n",
    "print(f\"- {final_data['target_addtocart'].sum():,} добавлений в корзину\")\n",
    "print(f\"-  {final_data['was_purchased'].sum():,} покупок\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275d74e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac17fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Добавляем рейтинг\n",
    "final_data['rating_count'] = final_data.groupby('item_id')['visitor_id'].transform('count')\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "final_data['rating'] = scaler.fit_transform(final_data[['rating_count']])\n",
    "\n",
    "# Удаляем временную колонку\n",
    "final_data = final_data.drop('rating_count', axis=1)\n",
    "\n",
    "# Проверяем\n",
    "print(final_data[['item_id', 'rating']].head())\n",
    "print(f\"Rating range: {final_data['rating'].min():.3f} - {final_data['rating'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21190ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем информацию о доступности товаров\n",
    "\n",
    "availability = item_properties[item_properties['property'] == 'available']\\\n",
    "    .sort_values('timestamp')\\\n",
    "    .drop_duplicates('item_id', keep='last')[['item_id', 'value']]\\\n",
    "    .rename(columns={'value': 'available'})\n",
    "\n",
    "final_data = final_data.merge(availability, on='item_id', how='left')\n",
    "final_data['available'] = final_data['available'].fillna('0')\n",
    "\n",
    "# Преобразуем формат времени\n",
    "final_data['timestamp'] = pd.to_datetime(final_data['timestamp'], unit='ms').dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "# Создаем фичу day из timestamp\n",
    "final_data['day'] = pd.to_datetime(final_data['timestamp']).dt.day\n",
    "\n",
    "print(\"колонка day:\")\n",
    "print(f\"Уникальные значения: {sorted(final_data['day'].unique())}\")\n",
    "print(f\"Диапазон: {final_data['day'].min()} - {final_data['day'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad86f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ПРЕОБРАЗУЕМ transaction_id в бинарную фичу\n",
    "final_data['transaction_id'] = final_data['transaction_id'].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2105f3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Выбираем только нужные колонки для нового датасета\n",
    "optimal_columns = [\n",
    "    'timestamp',        # для split и аналитики\n",
    "    'visitor_id',       # идентификатор пользователя\n",
    "    'item_id',          # идентификатор товара\n",
    "    'event',            # тип события (view/addtocart/transaction)\n",
    "    'transaction_id',   # идентификатор транзакции\n",
    "    'hour',             # час дня (ML фича)\n",
    "    'day_of_week',      # день недели (ML фича) \n",
    "    'day',              # день месяца (ML фича)\n",
    "    'month',            # месяц (ML фича)\n",
    "    'category_id',      # категория товара\n",
    "    'parent_id',        # родительская категория\n",
    "    'rating',           # популярность товара\n",
    "    'available',        # доступность товара\n",
    "    'target_addtocart', # целевая переменная - добавление в корзину\n",
    "    #'was_purchased'     # целевая переменная - покупка\n",
    "]\n",
    "\n",
    "# Создаем оптимальный датасет\n",
    "final_data = final_data[optimal_columns].copy()\n",
    "\n",
    "print(f\"Размер: {final_data.shape}\")\n",
    "print(f\"Колонки: {list(final_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54438f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795fa948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Смотрим топ-10 товаров по рейтингу\n",
    "\n",
    "final_data.drop_duplicates(subset='item_id').sort_values('rating', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e76fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Смотрим топ по рейтингу среди купленных товаров\n",
    "\n",
    "final_data[final_data['target_addtocart']==1].drop_duplicates(subset='item_id').sort_values('rating', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8354a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем категориальные фичи в числовые для корреляции\n",
    "corr_data = final_data.copy()\n",
    "\n",
    "# 1. Преобразуем day_of_week в числа\n",
    "day_map = {'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, \n",
    "           'Friday': 4, 'Saturday': 5, 'Sunday': 6}\n",
    "corr_data['day_of_week_num'] = corr_data['day_of_week'].map(day_map)\n",
    "\n",
    "# 2. Преобразуем event в числа (one-hot будет слишком много, используем label encoding)\n",
    "event_map = {'view': 0, 'addtocart': 1, 'transaction': 2}\n",
    "corr_data['event_num'] = corr_data['event'].map(event_map)\n",
    "\n",
    "# 3. available уже числовой (0/1)\n",
    "corr_data['available'] = corr_data['available'].astype(int)\n",
    "\n",
    "# 4. transaction_id уже числовой (0/1)\n",
    "\n",
    "# Выбираем числовые колонки для корреляции\n",
    "numeric_columns = [\n",
    "    'hour', 'day_of_week_num', 'day', 'month', \n",
    "    'category_id', 'parent_id', 'rating', 'available',\n",
    "    'transaction_id', 'event_num',  # преобразованные фичи\n",
    "    'target_addtocart'              # основной таргет\n",
    "]\n",
    "\n",
    "# Удаляем пропуски для корреляции\n",
    "corr_matrix = corr_data[numeric_columns].dropna().corr()\n",
    "\n",
    "# Строим тепловую карту\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.3f', linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Матрица корреляции признаков с target_addtocart', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{ASSETS_DIR}/correlation_matrix_final.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdfe2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Корреляция с target_addtocart:\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "target_correlations = corr_matrix['target_addtocart'].sort_values(ascending=False)\n",
    "\n",
    "for feature, corr in target_correlations.items():\n",
    "    if feature != 'target_addtocart':\n",
    "        print(f\"{feature:20} : {corr:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dfa8c2",
   "metadata": {},
   "source": [
    "ЭТАП 4: Сохранение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5617cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка данных на пропуски\n",
    "print(\" ПРОВЕРКА ДАННЫХ:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "for col in final_data.columns:\n",
    "    null_count = final_data[col].isnull().sum()\n",
    "    if null_count > 0:\n",
    "        print(f\" {col}: {null_count:,} пропусков\")\n",
    "    else:\n",
    "        print(f\" {col}: OK\")\n",
    "\n",
    "print(f\"\\n Всего строк: {len(final_data):,}\")\n",
    "print(f\" Всего колонок: {len(final_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab119995",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 ПРОВЕРКА ЗНАЧЕНИЯ 0 В ПРИЗНАКАХ:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "print(f\"category_id = 0: {(final_data['category_id'] == 0).sum():,}\")\n",
    "print(f\"parent_id = 0: {(final_data['parent_id'] == 0).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d577c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим совпадение пропусков\n",
    "print(\"🔍 ПРОВЕРКА СОВПАДЕНИЯ ПРОПУСКОВ:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "same_nulls = (final_data['category_id'].isnull() == final_data['parent_id'].isnull()).all()\n",
    "print(f\"Пропуски совпадают: {same_nulls}\")\n",
    "\n",
    "if same_nulls:\n",
    "    null_count = final_data['category_id'].isnull().sum()\n",
    "    print(f\"Всего строк с пропусками: {null_count:,}\")\n",
    "    print(f\"Это {null_count/len(final_data)*100:.1f}% данных\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472fd61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 ДЕТАЛЬНЫЙ АНАЛИЗ ПРОПУСКОВ:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Разные комбинации пропусков\n",
    "only_category_null = (final_data['category_id'].isnull() & final_data['parent_id'].notnull()).sum()\n",
    "only_parent_null = (final_data['category_id'].notnull() & final_data['parent_id'].isnull()).sum()\n",
    "both_null = (final_data['category_id'].isnull() & final_data['parent_id'].isnull()).sum()\n",
    "\n",
    "print(f\"Только category_id пропущен: {only_category_null:,}\")\n",
    "print(f\"Только parent_id пропущен: {only_parent_null:,}\") \n",
    "print(f\"Оба пропущены: {both_null:,}\")\n",
    "print(f\"Всего пропусков category_id: {final_data['category_id'].isnull().sum():,}\")\n",
    "print(f\"Всего пропусков parent_id: {final_data['parent_id'].isnull().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5163a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на товары без категорий\n",
    "no_category_items = final_data[final_data['category_id'].isnull()]['item_id'].nunique()\n",
    "print(f\"📦 Уникальных товаров без категорий: {no_category_items:,}\")\n",
    "\n",
    "# Посмотрим есть ли у них взаимодействия\n",
    "no_category_events = final_data[final_data['category_id'].isnull()]['event'].value_counts()\n",
    "print(\"📊 События товаров без категорий:\")\n",
    "print(no_category_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad93f2",
   "metadata": {},
   "source": [
    "Причины оставить:\n",
    "1. 49K товаров - значительная часть ассортимента\n",
    " 2. 833 добавления в корзину - реальный спрос\n",
    " 3. 475 покупок - товары продаются\n",
    " 4. Могут быть новинки или товары в процессе категоризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b0cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['category_id'] = final_data['category_id'].fillna(-1).astype(int)\n",
    "final_data['parent_id'] = final_data['parent_id'].fillna(-1).astype(int)\n",
    "\n",
    "print(\" Данные сохранены, пропуски заполнены -1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74dc215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем\n",
    "final_data.to_parquet(f'{PATH_DATA}/final_data.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7723a1",
   "metadata": {},
   "source": [
    "Основные столбцы для коллабротивной фильтрации:  \n",
    "essential_cols = ['visitor_id', 'item_id', 'event', 'timestamp']  \n",
    "- visitor_id, item_id - для user-item матрицы  \n",
    "- event - для весов взаимодействий  \n",
    "- timestamp - для временного разделения  \n",
    "\n",
    "Фичи для гибридной модели:  \n",
    "- additional_features = ['category_id', 'parent_id', 'rating', 'available', 'hour', 'day', 'month']  \n",
    "  \n",
    "target_addtocart для оценки рекомендаций. Будем смотреть, рекомендуем ли товары которые добавляют в корзину"
   ]
  },
  {
   "cell_type": "raw",
   "id": "905db4ad",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import mlflow\n",
    "\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "EXPERIMENT_NAME = 'project_final_ml'\n",
    "#REGISTRY_MODEL_NAME = \"ranking_model\"\n",
    "\n",
    "RUN_NAME = 'data_preparation_eda'\n",
    "\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" \n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") \n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "# Проверяем, существует ли эксперимент\n",
    "try:\n",
    "    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if experiment:\n",
    "        experiment_id = experiment.experiment_id\n",
    "        print(f\" Эксперимент '{EXPERIMENT_NAME}' найден, ID: {experiment_id}\")\n",
    "    else:\n",
    "        experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "        print(f\" Создан новый эксперимент '{EXPERIMENT_NAME}', ID: {experiment_id}\")\n",
    "except Exception as e:\n",
    "    print(f\" Ошибка: {e}\")\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # Логируем ВСЕ файлы из папки EDA\n",
    "    mlflow.log_artifacts(ASSETS_DIR)\n",
    "    \n",
    "    # Логируем метрики качества данных из EDA (оригинальные ID)\n",
    "    mlflow.log_metric(\"total_events\", len(final_data))\n",
    "    mlflow.log_metric(\"unique_users\", final_data['visitor_id'].nunique())  # оригинальный\n",
    "    mlflow.log_metric(\"unique_items\", final_data['item_id'].nunique())     # оригинальный\n",
    "    mlflow.log_metric(\"data_coverage\", final_data['category_id'].notna().mean())\n",
    "    mlflow.log_metric(\"addtocart_rate\", final_data['target_addtocart'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa7a95",
   "metadata": {},
   "source": [
    "Разбиение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1564ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем данные на тренировочную, тестовую выборки.\n",
    "\n",
    "# Преобразуем timestamp в datetime\n",
    "final_data['timestamp'] = pd.to_datetime(final_data['timestamp'])\n",
    "\n",
    "# зададим точку разбиения\n",
    "train_test_global_time_split_date = pd.to_datetime(\"2015-08-01 00:00:00\")\n",
    "\n",
    "# Фильтрация данных на основе условия\n",
    "train_test_global_time_split_idx = final_data[\"timestamp\"] < train_test_global_time_split_date\n",
    "events_train = final_data[train_test_global_time_split_idx]\n",
    "events_test = final_data[~train_test_global_time_split_idx]\n",
    "\n",
    "print(events_train.shape)\n",
    "print(events_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd2a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(events_train['timestamp'].describe())\n",
    "display(events_test['timestamp'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d25858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество пользователей в train и test\n",
    "print(len(events_train[\"visitor_id\"].drop_duplicates()))\n",
    "print(len(events_test[\"visitor_id\"].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d421c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество пользователей в train и test\n",
    "users_train = events_train[\"visitor_id\"].drop_duplicates()\n",
    "users_test = events_test[\"visitor_id\"].drop_duplicates()\n",
    "# Количество пользователей, которые есть и в train, и в test\n",
    "common_users = set(users_train).intersection(set(users_test))\n",
    "\n",
    "print(len(users_train), len(users_test), len(common_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Холодные пользователи. Те кто есть в тест, но нет в трейн\n",
    "cold_users = users_test[~users_test.isin(common_users)]\n",
    "\n",
    "print(len(cold_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8e9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# анализ холодного старта\n",
    "items_in_train = set(events_train.item_id.unique())\n",
    "items_in_test = set(events_test.item_id.unique())\n",
    "items_diff = items_in_test.difference(items_in_train)\n",
    "\n",
    "print(f\"Идентификаторов товара в train: {len(items_in_train):,}\")\n",
    "print(f\"Идентификаторов товара в test: {len(items_in_test):,}\")\n",
    "print(f\"Новых идентификаторов товара в test (cold start): {len(items_diff):,} ({len(items_diff)/len(items_in_test)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e3695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дропаем items в test которых нет в train\n",
    "original_test_size = len(events_test)\n",
    "events_test = events_test[events_test['item_id'].isin(items_in_train)]\n",
    "print(f\"Test set после фильтрации: {len(events_test):,} (удалено {original_test_size - len(events_test):,} событий)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98084a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем\n",
    "items_in_test = set(events_test.item_id.unique())\n",
    "items_diff = items_in_test.difference(items_in_train)\n",
    "len(items_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b2e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train size: {len(events_train):,} ({len(events_train)/len(events)*100:.1f}%)\")\n",
    "print(f\"Test size: {len(events_test):,} ({len(events_test)/len(events)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62869a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем холодных пользователей\n",
    "cold_users.to_csv(f'{PATH_DATA}/cold_users.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826b749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba09eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим текущее состояние\n",
    "print(\"До кодирования:\")\n",
    "print(f\"Уникальных пользователей: {final_data['visitor_id'].nunique():,}\")\n",
    "print(f\"Min visitor_id: {final_data['visitor_id'].min()}\")\n",
    "print(f\"Max visitor_id: {final_data['visitor_id'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc00fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "!!! утечка данных\n",
    "\n",
    "# Пересоздаем кодировщик\n",
    "user_encoder = LabelEncoder()\n",
    "\n",
    "# Обучаем на уникальных пользователях\n",
    "user_encoder.fit(events_train[\"visitor_id\"].unique())\n",
    "\n",
    "# Применяем преобразование\n",
    "final_data[\"visitor_id_enc\"] = user_encoder.transform(final_data[\"visitor_id\"])\n",
    "events_train[\"visitor_id_enc\"] = user_encoder.transform(events_train[\"visitor_id\"])\n",
    "events_test[\"visitor_id_enc\"] = user_encoder.transform(events_test[\"visitor_id\"])\n",
    "\n",
    "print(\"\\n Пользователи закодированы\")\n",
    "print(f\"Уникальных пользователей: {len(user_encoder.classes_):,}\")\n",
    "print(f\"Min visitor_id_enc: {final_data['visitor_id_enc'].min()}\")\n",
    "print(f\"Max visitor_id_enc: {final_data['visitor_id_enc'].max()}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4cb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Создаем кодировщик ТОЛЬКО на train данных\n",
    "user_encoder = LabelEncoder()\n",
    "user_encoder.fit(events_train[\"visitor_id\"])\n",
    "\n",
    "print(f\" Кодировщик пользователей обучен на {len(user_encoder.classes_):,} пользователях из train\")\n",
    "\n",
    "# 2. Создаем копию DataFrame и добавляем колонку\n",
    "events_train = events_train.copy()\n",
    "events_train[\"visitor_id_enc\"] = user_encoder.transform(events_train[\"visitor_id\"])\n",
    "\n",
    "# 3. Фильтруем test данные - только известные пользователи\n",
    "original_test_size = len(events_test)\n",
    "events_test = events_test[events_test[\"visitor_id\"].isin(user_encoder.classes_)].copy()\n",
    "\n",
    "print(f\" Test отфильтрован: {original_test_size:,} → {len(events_test):,} событий\")\n",
    "print(f\"   Удалено {original_test_size - len(events_test):,} событий неизвестных пользователей\")\n",
    "\n",
    "# 4. Добавляем колонку в test данные\n",
    "events_test[\"visitor_id_enc\"] = user_encoder.transform(events_test[\"visitor_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Пример закодированных пользователей:\")\n",
    "print(events_train[['visitor_id', 'visitor_id_enc']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc651f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "!!! утечка данных\n",
    "\n",
    "# Создаем кодировщик для товаров\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "# Обучаем на уникальных товарах из final_data\n",
    "item_encoder.fit(final_data[\"item_id\"].unique())\n",
    "\n",
    "# Применяем кодировку ко всем датасетам\n",
    "final_data[\"item_id_enc\"] = item_encoder.transform(final_data[\"item_id\"])\n",
    "events_train[\"item_id_enc\"] = item_encoder.transform(events_train[\"item_id\"])\n",
    "events_test[\"item_id_enc\"] = item_encoder.transform(events_test[\"item_id\"])\n",
    "\n",
    "print(\" Товары закодированы\")\n",
    "print(f\"Уникальных товаров: {len(item_encoder.classes_):,}\")\n",
    "print(f\"Min item_id_enc: {final_data['item_id_enc'].min()}\")\n",
    "print(f\"Max item_id_enc: {final_data['item_id_enc'].max()}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655abb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ПРАВИЛЬНОЕ КОДИРОВАНИЕ ТОВАРОВ ===\")\n",
    "\n",
    "# 1. Создаем кодировщик ТОЛЬКО на train данных\n",
    "item_encoder = LabelEncoder()\n",
    "item_encoder.fit(events_train[\"item_id\"])\n",
    "\n",
    "print(f\"✅ Кодировщик товаров обучен на {len(item_encoder.classes_):,} товарах из train\")\n",
    "\n",
    "# 2. Кодируем train данные\n",
    "events_train.loc[:, \"item_id_enc\"] = item_encoder.transform(events_train[\"item_id\"])\n",
    "\n",
    "# 3. Фильтруем test данные - только известные товары\n",
    "original_test_size = len(events_test)\n",
    "events_test = events_test[events_test[\"item_id\"].isin(item_encoder.classes_)].copy()\n",
    "\n",
    "print(f\"✅ Test отфильтрован: {original_test_size:,} → {len(events_test):,} событий\")\n",
    "print(f\"   Удалено {original_test_size - len(events_test):,} событий неизвестных товаров\")\n",
    "\n",
    "# 4. Кодируем test данные\n",
    "events_test.loc[:, \"item_id_enc\"] = item_encoder.transform(events_test[\"item_id\"])\n",
    "\n",
    "print(\"🎉 Кодирование товаров завершено БЕЗ УТЕЧЕК!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b356546",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Пример закодированных товаров:\")\n",
    "print(events_train[['item_id', 'item_id_enc']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b6f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Проверка закодированных данных:\")\n",
    "print(f\"Уникальных visitor_id_enc: {events_train['visitor_id_enc'].nunique()}\")\n",
    "print(f\"Уникальных item_id_enc: {events_train['item_id_enc'].nunique()}\")\n",
    "print(f\"Min visitor_id_enc: {events_train['visitor_id_enc'].min()}\")\n",
    "print(f\"Max visitor_id_enc: {events_train['visitor_id_enc'].max()}\")\n",
    "print(f\"Min item_id_enc: {events_train['item_id_enc'].min()}\")\n",
    "print(f\"Max item_id_enc: {events_train['item_id_enc'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ed676",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "!!! утечка данных\n",
    "\n",
    "# Создаем кодировщик для категорий\n",
    "category_encoder = LabelEncoder()\n",
    "\n",
    "# Обучаем на уникальных категориях из final_data\n",
    "category_encoder.fit(final_data[\"category_id\"].unique())\n",
    "\n",
    "# Применяем кодировку ко всем датасетам\n",
    "final_data[\"category_id_enc\"] = category_encoder.transform(final_data[\"category_id\"])\n",
    "events_train[\"category_id_enc\"] = category_encoder.transform(events_train[\"category_id\"])\n",
    "events_test[\"category_id_enc\"] = category_encoder.transform(events_test[\"category_id\"])\n",
    "\n",
    "print(\" Категории закодированы\")\n",
    "print(f\"Уникальных категорий: {len(category_encoder.classes_):,}\")\n",
    "print(f\"Min category_id_enc: {final_data['category_id_enc'].min()}\")\n",
    "print(f\"Max category_id_enc: {final_data['category_id_enc'].max()}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc683a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Создаем кодировщик ТОЛЬКО на train данных\n",
    "category_encoder = LabelEncoder()\n",
    "category_encoder.fit(events_train[\"category_id\"])\n",
    "\n",
    "print(f\"✅ Кодировщик категорий обучен на {len(category_encoder.classes_):,} категориях из train\")\n",
    "\n",
    "# 2. Кодируем train данные\n",
    "events_train.loc[:, \"category_id_enc\"] = category_encoder.transform(events_train[\"category_id\"])\n",
    "\n",
    "# 3. Для test данных используем .apply с обработкой неизвестных категорий\n",
    "events_test.loc[:, \"category_id_enc\"] = events_test[\"category_id\"].apply(\n",
    "    lambda x: category_encoder.transform([x])[0] if x in category_encoder.classes_ else -1\n",
    ")\n",
    "\n",
    "print(\"🎉 Кодирование категорий завершено БЕЗ УТЕЧЕК!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd5b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Пример закодированных категорий:\")\n",
    "print(events_train[['category_id', 'category_id_enc']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d240e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим кодировку всех специальных значений\n",
    "print(\"=== ПРАВИЛЬНАЯ ПРОВЕРКА КОДИРОВКИ КАТЕГОРИЙ ===\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Проверяем специальные значения на ИСПРАВЛЕННОМ кодировщике\n",
    "print(\" Проверка специальных значений:\")\n",
    "try:\n",
    "    minus_one_code = category_encoder.transform([-1])[0]\n",
    "    print(f\" category_id = -1 → category_id_enc = {minus_one_code}\")\n",
    "except ValueError:\n",
    "    print(\" category_id = -1 не найден в кодировщике\")\n",
    "\n",
    "# 2. Проверяем на ИСПРАВЛЕННЫХ ДАННЫХ (только train)\n",
    "print(f\"\\n ТОП-5 самых частых category_id_enc в TRAIN:\")\n",
    "category_enc_counts = events_train['category_id_enc'].value_counts().head()\n",
    "\n",
    "for code, count in category_enc_counts.items():\n",
    "    try:\n",
    "        original_id = category_encoder.inverse_transform([code])[0]\n",
    "        print(f\"   code {code:4d} (original {original_id:4d}): {count:>8,} строк\")\n",
    "    except:\n",
    "        print(f\"   code {code:4d}: {count:>8,} строк (неизвестная категория)\")\n",
    "\n",
    "# 3. Проверяем код 0 на ИСПРАВЛЕННЫХ ДАННЫХ\n",
    "print(f\"\\n ДЕТАЛЬНЫЙ АНАЛИЗ КОДА 0 в TRAIN:\")\n",
    "zero_mask = events_train['category_id_enc'] == 0\n",
    "\n",
    "if zero_mask.any():\n",
    "    try:\n",
    "        zero_original = category_encoder.inverse_transform([0])[0]\n",
    "        zero_count = zero_mask.sum()\n",
    "        print(f\" category_id_enc = 0 соответствует category_id = {zero_original}\")\n",
    "        print(f\"   Количество строк: {zero_count:,}\")\n",
    "        \n",
    "        # События для этого кода\n",
    "        zero_events = events_train[zero_mask]['event'].value_counts()\n",
    "        print(\"   События для этого кода:\")\n",
    "        for event, count in zero_events.items():\n",
    "            print(f\"     - {event}: {count:,}\")\n",
    "    except:\n",
    "        print(\" Не удалось определить оригинальную категорию для кода 0\")\n",
    "else:\n",
    "    print(\"ℹ  Код 0 не используется в train данных\")\n",
    "\n",
    "# 4. Проверяем coverage в test данных\n",
    "print(f\"\\n ПОКРЫТИЕ КАТЕГОРИЙ В TEST:\")\n",
    "unknown_categories_test = (~events_test['category_id'].isin(category_encoder.classes_)).sum()\n",
    "total_test_categories = len(events_test)\n",
    "\n",
    "print(f\"   Неизвестных категорий в test: {unknown_categories_test:,}\")\n",
    "print(f\"   Всего событий в test: {total_test_categories:,}\")\n",
    "print(f\"   Доля неизвестных категорий: {unknown_categories_test/total_test_categories*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd8c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем кодировщик для родительских категорий\n",
    "parent_encoder = LabelEncoder()\n",
    "\n",
    "# Обучаем на уникальных родительских категориях из final_data\n",
    "parent_encoder.fit(final_data[\"parent_id\"].unique())\n",
    "\n",
    "# Применяем кодировку ко всем датасетам\n",
    "final_data[\"parent_id_enc\"] = parent_encoder.transform(final_data[\"parent_id\"])\n",
    "events_train[\"parent_id_enc\"] = parent_encoder.transform(events_train[\"parent_id\"])\n",
    "events_test[\"parent_id_enc\"] = parent_encoder.transform(events_test[\"parent_id\"])\n",
    "\n",
    "print(\" Родительские категории закодированы\")\n",
    "print(f\"Уникальных родительских категорий: {len(parent_encoder.classes_):,}\")\n",
    "print(f\"Min parent_id_enc: {final_data['parent_id_enc'].min()}\")\n",
    "print(f\"Max parent_id_enc: {final_data['parent_id_enc'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af08761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Создаем кодировщик ТОЛЬКО на train данных\n",
    "parent_encoder = LabelEncoder()\n",
    "parent_encoder.fit(events_train[\"parent_id\"])\n",
    "\n",
    "print(f\"✅ Кодировщик родительских категорий обучен на {len(parent_encoder.classes_):,} категориях из train\")\n",
    "\n",
    "# 2. Кодируем train данные\n",
    "events_train.loc[:, \"parent_id_enc\"] = parent_encoder.transform(events_train[\"parent_id\"])\n",
    "\n",
    "# 3. Для test данных используем .apply с обработкой неизвестных категорий\n",
    "events_test.loc[:, \"parent_id_enc\"] = events_test[\"parent_id\"].apply(\n",
    "    lambda x: parent_encoder.transform([x])[0] if x in parent_encoder.classes_ else -1\n",
    ")\n",
    "\n",
    "print(\"🎉 Кодирование родительских категорий завершено БЕЗ УТЕЧЕК!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f45af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Пример закодированных родительских категорий:\")\n",
    "print(events_train[['parent_id', 'parent_id_enc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712932e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== СОХРАНЕНИЕ ВСЕХ ЧИСТЫХ ДАННЫХ ===\")\n",
    "import joblib\n",
    "\n",
    "# 1. Сохраняем исправленные данные\n",
    "events_train_final = events_train\n",
    "events_test_final = events_test\n",
    "\n",
    "events_train_final.to_parquet(f'{PATH_DATA}/events_train_clean.parquet', index=False)\n",
    "events_test_final.to_parquet(f'{PATH_DATA}/events_test_clean.parquet', index=False)\n",
    "\n",
    "# 2. Сохраняем ВСЕ кодировщики\n",
    "joblib.dump(user_encoder, f'{PATH_DATA}/user_encoder.pkl')\n",
    "joblib.dump(item_encoder, f'{PATH_DATA}/item_encoder.pkl') \n",
    "joblib.dump(category_encoder, f'{PATH_DATA}/category_encoder.pkl')\n",
    "joblib.dump(parent_encoder, f'{PATH_DATA}/parent_encoder.pkl')\n",
    "\n",
    "print(\"🎉 ВСЕ ДАННЫЕ И КОДИРОВЩИКИ СОХРАНЕНЫ!\")\n",
    "print(f\"💾 Train: {len(events_train_final):,} событий\")\n",
    "print(f\"💾 Test:  {len(events_test_final):,} событий\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c6a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Финальная статистика\n",
    "print(f\"\\n=== ФИНАЛЬНАЯ СТАТИСТИКА ЧИСТЫХ ДАННЫХ ===\")\n",
    "print(f\"👥 Пользователей: {events_train_final['visitor_id_enc'].nunique():,} train, {events_test_final['visitor_id_enc'].nunique():,} test\")\n",
    "print(f\"🛍️ Товаров: {events_train_final['item_id_enc'].nunique():,} train, {events_test_final['item_id_enc'].nunique():,} test\")\n",
    "print(f\"📂 Категорий: {events_train_final['category_id_enc'].nunique():,} train, {events_test_final['category_id_enc'].nunique():,} test\")\n",
    "print(f\"🏷️ Родительских категорий: {events_train_final['parent_id_enc'].nunique():,} train, {events_test_final['parent_id_enc'].nunique():,} test\")\n",
    "\n",
    "# 4. Проверка чистоты данных\n",
    "print(f\"\\n=== ПРОВЕРКА ОТСУТСТВИЯ УТЕЧЕК ===\")\n",
    "all_users_clean = events_test_final['visitor_id_enc'].isin(events_train_final['visitor_id_enc']).all()\n",
    "all_items_clean = events_test_final['item_id_enc'].isin(events_train_final['item_id_enc']).all()\n",
    "all_categories_clean = events_test_final['category_id_enc'].isin(events_train_final['category_id_enc']).all()\n",
    "all_parents_clean = events_test_final['parent_id_enc'].isin(events_train_final['parent_id_enc']).all()\n",
    "\n",
    "print(f\"✅ Все пользователи test есть в train: {all_users_clean}\")\n",
    "print(f\"✅ Все товары test есть в train: {all_items_clean}\")\n",
    "print(f\"✅ Все категории test есть в train: {all_categories_clean}\")\n",
    "print(f\"✅ Все родительские категории test есть в train: {all_parents_clean}\")\n",
    "\n",
    "print(f\"\\n🎉 ВСЕ DATA LEAKAGE ИСПРАВЛЕНЫ! МОЖНО ПЕРЕОБУЧАТЬ МОДЕЛИ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c12e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== СОХРАНЕНИЕ ЧИСТЫХ ДАННЫХ ===\")\n",
    "\n",
    "# Используем твой существующий код\n",
    "final_columns = ['timestamp',\n",
    "                 'visitor_id_enc', 'item_id_enc', 'event', 'transaction_id', \n",
    "                 'hour', 'day_of_week', 'day', 'month', 'category_id_enc', 'parent_id_enc', \n",
    "                 'rating', 'available', 'target_addtocart'\n",
    "                 ]\n",
    "\n",
    "events_train_final = events_train[final_columns].copy()\n",
    "events_test_final = events_test[final_columns].copy()\n",
    "\n",
    "events_train_final.to_parquet(f'{PATH_DATA}/events_train_clean.parquet', index=False)\n",
    "events_test_final.to_parquet(f'{PATH_DATA}/events_test_clean.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c24857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Сохраняем ВСЕ кодировщики\n",
    "joblib.dump(user_encoder, f'{PATH_DATA}/user_encoder.pkl')\n",
    "joblib.dump(item_encoder, f'{PATH_DATA}/item_encoder.pkl') \n",
    "joblib.dump(category_encoder, f'{PATH_DATA}/category_encoder.pkl')\n",
    "joblib.dump(parent_encoder, f'{PATH_DATA}/parent_encoder.pkl')\n",
    "\n",
    "print(\" Кодировщики сохранены\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a77bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\" ВСЕ ДАННЫЕ И КОДИРОВЩИКИ СОХРАНЕНЫ!\")\n",
    "print(f\" Train: {len(events_train_final):,} событий\")\n",
    "print(f\" Test:  {len(events_test_final):,} событий\")\n",
    "\n",
    "# Финальная статистика\n",
    "print(f\"\\n=== ФИНАЛЬНАЯ СТАТИСТИКА ЧИСТЫХ ДАННЫХ ===\")\n",
    "print(f\" Пользователей: {events_train_final['visitor_id_enc'].nunique():,} train, {events_test_final['visitor_id_enc'].nunique():,} test\")\n",
    "print(f\" Товаров: {events_train_final['item_id_enc'].nunique():,} train, {events_test_final['item_id_enc'].nunique():,} test\")\n",
    "print(f\" Категорий: {events_train_final['category_id_enc'].nunique():,} train, {events_test_final['category_id_enc'].nunique():,} test\")\n",
    "print(f\" Родительских категорий: {events_train_final['parent_id_enc'].nunique():,} train, {events_test_final['parent_id_enc'].nunique():,} test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d6fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_train_final"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b19cbc36",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import mlflow\n",
    "\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "EXPERIMENT_NAME = 'project_final_ml'\n",
    "RUN_NAME = 'clean_data_encoders'  # меняем только название RUN\n",
    "\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" \n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") \n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "# Проверяем, существует ли эксперимент\n",
    "try:\n",
    "    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if experiment:\n",
    "        experiment_id = experiment.experiment_id\n",
    "        print(f\" Эксперимент '{EXPERIMENT_NAME}' найден, ID: {experiment_id}\")\n",
    "    else:\n",
    "        experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "        print(f\" Создан новый эксперимент '{EXPERIMENT_NAME}', ID: {experiment_id}\")\n",
    "except Exception as e:\n",
    "    print(f\" Ошибка: {e}\")\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# ВТОРОЙ ЭКСПЕРИМЕНТ\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # Логируем подготовленные данные\n",
    "    mlflow.log_artifact(f'{PATH_DATA}/events_train_clean.parquet')\n",
    "    mlflow.log_artifact(f'{PATH_DATA}/events_test_clean.parquet')\n",
    "\n",
    "    # Логируем информацию о колонках\n",
    "    mlflow.log_param(\"train_columns\", str(list(events_train_final.columns)))\n",
    "    mlflow.log_param(\"test_columns\", str(list(events_test_final.columns)))\n",
    "    mlflow.log_param(\"common_columns\", str(list(set(events_train_final.columns) & set(events_test_final.columns))))\n",
    "    \n",
    "    # Логируем типы данных\n",
    "    mlflow.log_param(\"train_dtypes\", str(events_train_final.dtypes.to_dict()))\n",
    "    mlflow.log_param(\"test_dtypes\", str(events_test_final.dtypes.to_dict()))\n",
    "    \n",
    "    # Логируем кодировщики\n",
    "    mlflow.log_artifact(f'{PATH_DATA}/user_encoder.pkl')\n",
    "    mlflow.log_artifact(f'{PATH_DATA}/item_encoder.pkl') \n",
    "    mlflow.log_artifact(f'{PATH_DATA}/category_encoder.pkl')\n",
    "    mlflow.log_artifact(f'{PATH_DATA}/parent_encoder.pkl')\n",
    "    \n",
    "    # Логируем метрики очищенных данных\n",
    "    mlflow.log_metric(\"train_size\", len(events_train_final))\n",
    "    mlflow.log_metric(\"test_size\", len(events_test_final))\n",
    "    mlflow.log_metric(\"users_encoded\", events_train_final['visitor_id_enc'].nunique())\n",
    "    mlflow.log_metric(\"items_encoded\", events_test_final['item_id_enc'].nunique())\n",
    "    \n",
    "    print(f\" Очищенные данные и кодировщики залогированы в run: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548e63a",
   "metadata": {},
   "source": [
    "# Очистка памяти\n",
    "Здесь, может понадобится очистка памяти для высвобождения ресурсов для выполнения кода ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "import mlflow\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "import psycopg2 as psycopg\n",
    "\n",
    "import pickle\n",
    "\n",
    "#from catboost import CatBoostClassifier, Pool\n",
    "import sklearn.preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a071ed",
   "metadata": {},
   "source": [
    "Директория"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "# Пути и названия файлов заданы в виде параметров\n",
    "PATH_DATA = 'data'\n",
    "\n",
    "PATH_MODELS = 'models'\n",
    "MODEL_FILE = 'model.pkl'\n",
    "\n",
    "ASSETS_DIR = 'mlflow_server/eda_plots'\n",
    "\n",
    "#TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "#TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "#EXPERIMENT_NAME = 'project_final_ml'\n",
    "#REGISTRY_MODEL_NAME = \"ranking_model\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6461e24",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ[\"S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" \n",
    "os.environ[\"S3_BUCKET_NAME\"] = os.getenv(\"S3_BUCKET_NAME\") \n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") \n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb6001",
   "metadata": {},
   "source": [
    "# Рекомендации  \n",
    "\n",
    "# Топ товаров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d20cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем\n",
    "events_train_clean = pd.read_parquet(f'{PATH_DATA}/events_train_clean.parquet')\n",
    "\n",
    "# Считаем популярность товаров\n",
    "item_popularity = events_train_clean \\\n",
    "    .groupby(\"item_id_enc\").agg(\n",
    "        users=(\"visitor_id_enc\", \"nunique\"), \n",
    "        avg_rating=(\"rating\", \"mean\")\n",
    "    ).reset_index()\n",
    "\n",
    "# Топ-50 товаров\n",
    "top_items = item_popularity.sort_values('users', ascending=False).head(500)\n",
    "top_items['rank'] = range(1, len(top_items) + 1)\n",
    "\n",
    "# Создаем папку если не существует\n",
    "os.makedirs(f'{PATH_DATA}/recommendations', exist_ok=True)\n",
    "\n",
    "# Сохраняем\n",
    "top_items.to_parquet(f'{PATH_DATA}/recommendations/top_popular.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c333f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на топ-15 самых популярных товаров\n",
    "top_15 = top_items.head(15)\n",
    "print(\"Топ-15 самых популярных товаров:\")\n",
    "print(top_15[['item_id_enc', 'users', 'avg_rating', 'rank']])\n",
    "\n",
    "# Визуализируем\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh([str(x) for x in top_15['item_id_enc']], top_15['users'])\n",
    "plt.title('Топ-15 товаров по количеству уникальных пользователей')\n",
    "plt.xlabel('Количество пользователей')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Самый популярный товар: {top_15.iloc[0]['item_id_enc']}\")\n",
    "print(f\"Количество пользователей: {top_15.iloc[0]['users']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935143b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import joblib\n",
    "\n",
    "# Загружаем данные\n",
    "cold_users = pd.read_csv(f'{PATH_DATA}/cold_users.csv')\n",
    "top_items = pd.read_parquet(f'{PATH_DATA}/recommendations/top_popular.parquet')\n",
    "events_test_clean = pd.read_parquet(f'{PATH_DATA}/events_test_clean.parquet')\n",
    "\n",
    "# Загружаем кодировщик\n",
    "user_encoder = joblib.load(f'{PATH_DATA}/user_encoder.pkl')\n",
    "\n",
    "print(\"=== АНАЛИЗ РЕКОМЕНДАЦИЙ ДЛЯ ХОЛОДНЫХ ПОЛЬЗОВАТЕЛЕЙ ===\")\n",
    "print(f\"Всего холодных пользователей: {len(cold_users):,}\")\n",
    "print(f\"Топ рекомендаций: {len(top_items)} товаров\")\n",
    "\n",
    "# ФИЛЬТРУЕМ cold_users - оставляем только тех, кто есть в кодировщике\n",
    "known_cold_users = cold_users[cold_users['visitor_id'].isin(user_encoder.classes_)].copy()\n",
    "\n",
    "print(f\"Холодных пользователей, известных модели: {len(known_cold_users):,}\")\n",
    "print(f\"Неизвестных холодных пользователей: {len(cold_users) - len(known_cold_users):,}\")\n",
    "\n",
    "# Если есть известные холодные пользователи - анализируем их\n",
    "if len(known_cold_users) > 0:\n",
    "    # Кодируем ТОЛЬКО известных холодных пользователей\n",
    "    known_cold_users['visitor_id_enc'] = user_encoder.transform(known_cold_users['visitor_id'])\n",
    "\n",
    "    # Анализируем события известных холодных пользователей в тестовой выборке\n",
    "    cold_users_events = events_test_clean[events_test_clean['visitor_id_enc'].isin(known_cold_users['visitor_id_enc'])]\n",
    "\n",
    "    print(f\"Событий известных холодных пользователей: {len(cold_users_events):,}\")\n",
    "    print(f\"Уникальных товаров у холодных пользователей: {cold_users_events['item_id_enc'].nunique():,}\")\n",
    "\n",
    "    if len(cold_users_events) > 0:\n",
    "        # Проверяем совпадения с топ рекомендациями\n",
    "        cold_events_with_recs = cold_users_events.merge(\n",
    "            top_items[['item_id_enc', 'rank']], \n",
    "            on='item_id_enc', \n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # 1. Анализ покрытия пользователей\n",
    "        users_with_matches = cold_events_with_recs[\n",
    "            cold_events_with_recs['rank'].notna()\n",
    "        ]['visitor_id_enc'].nunique()\n",
    "\n",
    "        print(f\"\\n=== ПОКРЫТИЕ ПОЛЬЗОВАТЕЛЕЙ ===\")\n",
    "        print(f\"Пользователей с совпадениями: {users_with_matches:,}\")\n",
    "        print(f\"Доля пользователей с совпадениями: {users_with_matches/len(known_cold_users)*100:.1f}%\")\n",
    "\n",
    "        # 2. Анализ покрытия событий\n",
    "        events_with_matches = cold_events_with_recs['rank'].notna().sum()\n",
    "        print(f\"\\n=== ПОКРЫТИЕ СОБЫТИЙ ===\")\n",
    "        print(f\"Событий с совпадениями: {events_with_matches:,}\")\n",
    "        print(f\"Доля событий с совпадениями: {events_with_matches/len(cold_users_events)*100:.1f}%\")\n",
    "\n",
    "        # 3. Детальный анализ покрытия по пользователям\n",
    "        user_coverage = cold_events_with_recs.groupby('visitor_id_enc').agg(\n",
    "            total_events=('item_id_enc', 'count'),\n",
    "            matched_events=('rank', lambda x: x.notna().sum())\n",
    "        ).reset_index()\n",
    "\n",
    "        user_coverage['coverage_ratio'] = user_coverage['matched_events'] / user_coverage['total_events']\n",
    "\n",
    "        print(f\"\\n=== ДЕТАЛЬНЫЙ АНАЛИЗ ПОКРЫТИЯ ===\")\n",
    "        print(f\"Пользователей без совпадений: {(user_coverage['matched_events'] == 0).sum():,}\")\n",
    "        print(f\"Доля пользователей без совпадений: {(user_coverage['matched_events'] == 0).mean()*100:.1f}%\")\n",
    "        \n",
    "        if len(user_coverage[user_coverage['matched_events'] > 0]) > 0:\n",
    "            print(f\"Среднее покрытие (у кого есть совпадения): {user_coverage[user_coverage['matched_events'] > 0]['coverage_ratio'].mean()*100:.1f}%\")\n",
    "        else:\n",
    "            print(f\"Среднее покрытие (у кого есть совпадения): 0%\")\n",
    "        \n",
    "        print(f\"Общее среднее покрытие: {user_coverage['coverage_ratio'].mean()*100:.1f}%\")\n",
    "\n",
    "        # 4. Анализ по типам событий\n",
    "        print(f\"\\n=== АНАЛИЗ ПО ТИПАМ СОБЫТИЙ ===\")\n",
    "        event_types_analysis = cold_events_with_recs.groupby('event').agg(\n",
    "            total=('visitor_id_enc', 'count'),\n",
    "            matched=('rank', lambda x: x.notna().sum())\n",
    "        ).reset_index()\n",
    "        event_types_analysis['match_rate'] = event_types_analysis['matched'] / event_types_analysis['total'] * 100\n",
    "        print(event_types_analysis)\n",
    "    else:\n",
    "        print(\" Нет событий для анализа\")\n",
    "else:\n",
    "    print(\" ВЫВОД: Cold start проблема подтверждена!\")\n",
    "    print(\"   - 0 холодных пользователей известны модели\")\n",
    "    print(\"   - Для них нужны отдельные подходы:\")\n",
    "    print(\"     • Топ-популярные товары\")\n",
    "    print(\"     • Демографические рекомендации\") \n",
    "    print(\"     • Content-based подходы\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0520f9bb",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Логируем top_500 в MLflow\n",
    "\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "EXPERIMENT_NAME = 'project_final_ml'\n",
    "RUN_NAME = 'exp_top_popular_500'\n",
    "\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" \n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") \n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "# Проверяем эксперимент\n",
    "try:\n",
    "    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if experiment:\n",
    "        experiment_id = experiment.experiment_id\n",
    "        print(f\" Эксперимент '{EXPERIMENT_NAME}' найден\")\n",
    "    else:\n",
    "        experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "        print(f\" Создан эксперимент '{EXPERIMENT_NAME}'\")\n",
    "except Exception as e:\n",
    "    print(f\" Ошибка: {e}\")\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# Загружаем актуальные top_items\n",
    "top_items = pd.read_parquet(f'{PATH_DATA}/recommendations/top_popular.parquet')\n",
    "\n",
    "# Логируем\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # Логируем артефакт\n",
    "    mlflow.log_artifact(f'{PATH_DATA}/recommendations/top_popular.parquet')\n",
    "    \n",
    "    # Логируем метрики top-popular\n",
    "    mlflow.log_metric(\"top_items_count\", len(top_items))\n",
    "    mlflow.log_metric(\"max_users_per_item\", top_items['users'].max())\n",
    "    mlflow.log_metric(\"min_users_top_500\", top_items['users'].min())\n",
    "    mlflow.log_metric(\"avg_rating_top_items\", top_items['avg_rating'].mean())\n",
    "    mlflow.log_metric(\"total_unique_users\", top_items['users'].sum())\n",
    "    \n",
    "    # Логируем параметры\n",
    "    mlflow.log_param(\"strategy\", \"top_popular\")\n",
    "    mlflow.log_param(\"items_count\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b077fb",
   "metadata": {},
   "source": [
    "# Персональные  \n",
    "\n",
    "Рассчитаем персональные рекомендации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b917ede1",
   "metadata": {},
   "source": [
    "Здесь, может понадобится очистка памяти для высвобождения ресурсов для выполнения кода ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43083c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import numpy as np\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "import pandas as pd\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ed9e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "# Пути и названия файлов заданы в виде параметров\n",
    "PATH_DATA = 'data'\n",
    "\n",
    "PATH_MODELS = 'models'\n",
    "MODEL_FILE = 'model.pkl'\n",
    "\n",
    "ASSETS_DIR = 'mlflow_server/eda_plots'\n",
    "\n",
    "#TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "#TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "#EXPERIMENT_NAME = 'project_final_ml'\n",
    "#REGISTRY_MODEL_NAME = \"ranking_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15f595eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ДИАГНОСТИКА ДАННЫХ ===\n",
      "Размер events_train_clean: 1,898,746 строк\n",
      "Уникальных пользователей: 962,528\n",
      "Уникальных товаров: 199,689\n",
      "\n",
      "=== АНАЛИЗ СОБЫТИЙ ===\n",
      " - view: 1,836,691 (96.7%)\n",
      " - addtocart: 46,599 (2.5%)\n",
      " - transaction: 15,456 (0.8%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Загружаем данные\n",
    "events_train_clean = pd.read_parquet(f'{PATH_DATA}/events_train_clean.parquet')\n",
    "\n",
    "print(\"=== ДИАГНОСТИКА ДАННЫХ ===\")\n",
    "print(f\"Размер events_train_clean: {len(events_train_clean):,} строк\")\n",
    "print(f\"Уникальных пользователей: {events_train_clean['visitor_id_enc'].nunique():,}\")\n",
    "print(f\"Уникальных товаров: {events_train_clean['item_id_enc'].nunique():,}\")\n",
    "\n",
    "# 2. Анализ событий\n",
    "print(f\"\\n=== АНАЛИЗ СОБЫТИЙ ===\")\n",
    "event_counts = events_train_clean['event'].value_counts()\n",
    "for event, count in event_counts.items():\n",
    "    percentage = (count / len(events_train_clean)) * 100\n",
    "    print(f\" - {event}: {count:,} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96816fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== УСТАНАВЛИВАЕМ ВЕСА ПО ЦЕЛИ ПРОЕКТА ===\n",
      " Веса установлены по цели проекта:\n",
      "   - view: 1.0 (базовый)\n",
      "   - addtocart: 10.0 (ГЛАВНАЯ ЦЕЛЬ!)\n",
      "   - transaction: 5.0 (второстепенное)\n",
      "\n",
      "=== АГРЕГИРУЕМ ВЗАИМОДЕЙСТВИЯ ===\n",
      "До агрегации: 1,898,746 строк\n",
      "После агрегации: 1,472,639 строк\n"
     ]
    }
   ],
   "source": [
    "# 3. Устанавливаем веса ПО ЦЕЛИ ПРОЕКТА (добавления в корзину)\n",
    "print(f\"\\n=== УСТАНАВЛИВАЕМ ВЕСА ПО ЦЕЛИ ПРОЕКТА ===\")\n",
    "events_train_fixed = events_train_clean.copy()\n",
    "events_train_fixed['weight'] = 1.0                    # просмотры\n",
    "events_train_fixed.loc[events_train_fixed['target_addtocart'] == 1, 'weight'] = 10.0  # КОРЗИНА - ГЛАВНОЕ!\n",
    "events_train_fixed.loc[events_train_clean['event'] == 'transaction', 'weight'] = 5.0   # покупки\n",
    "\n",
    "print(\" Веса установлены по цели проекта:\")\n",
    "print(\"   - view: 1.0 (базовый)\")\n",
    "print(\"   - addtocart: 10.0 (ГЛАВНАЯ ЦЕЛЬ!)\") \n",
    "print(\"   - transaction: 5.0 (второстепенное)\")\n",
    "\n",
    "# 4. Агрегируем взаимодействия\n",
    "print(f\"\\n=== АГРЕГИРУЕМ ВЗАИМОДЕЙСТВИЯ ===\")\n",
    "aggregated_interactions = events_train_fixed.groupby(\n",
    "    ['visitor_id_enc', 'item_id_enc']\n",
    ").agg({\n",
    "    'weight': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"До агрегации: {len(events_train_fixed):,} строк\")\n",
    "print(f\"После агрегации: {len(aggregated_interactions):,} строк\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0b45130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== СОЗДАЕМ МАТРИЦУ ===\n",
      "Размерность матрицы: (962528, 199689)\n",
      "Ненулевых элементов: 1,472,639\n",
      "Диапазон весов: 1.0 - 10.0\n",
      "Заполненность матрицы: 0.000008%\n",
      "Память для матрицы: 14.91 MB\n"
     ]
    }
   ],
   "source": [
    "# 5. Создаем матрицу взаимодействий\n",
    "print(f\"\\n=== СОЗДАЕМ МАТРИЦУ ===\")\n",
    "user_item_matrix = scipy.sparse.csr_matrix((\n",
    "    aggregated_interactions['weight'].values,\n",
    "    (aggregated_interactions['visitor_id_enc'].values, aggregated_interactions['item_id_enc'].values)),\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "print(f\"Размерность матрицы: {user_item_matrix.shape}\")\n",
    "print(f\"Ненулевых элементов: {user_item_matrix.nnz:,}\")\n",
    "print(f\"Диапазон весов: {user_item_matrix.data.min():.1f} - {user_item_matrix.data.max():.1f}\")\n",
    "\n",
    "# Расчет заполненности матрицы\n",
    "sparsity = user_item_matrix.nnz / (user_item_matrix.shape[0] * user_item_matrix.shape[1])\n",
    "print(f\"Заполненность матрицы: {sparsity:.6f}%\")\n",
    "\n",
    "# Размер матрицы в памяти\n",
    "matrix_memory_mb = (user_item_matrix.data.nbytes + \n",
    "                   user_item_matrix.indices.nbytes + \n",
    "                   user_item_matrix.indptr.nbytes) / 1024**2\n",
    "print(f\"Память для матрицы: {matrix_memory_mb:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d9919ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ОБУЧАЕМ ALS ===\n",
      "Начинаем обучение...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/mle_projects/mle-project-final/.venv_final_project/lib/python3.10/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 4 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e1048509634b22b6af0bfe8dd52459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Модель обучена!\n"
     ]
    }
   ],
   "source": [
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "# 6. Обучаем ALS модель\n",
    "print(f\"\\n=== ОБУЧАЕМ ALS ===\")\n",
    "als_model = AlternatingLeastSquares(\n",
    "    factors=64,\n",
    "    iterations=50, \n",
    "    regularization=0.05,\n",
    "    alpha=2.0,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Начинаем обучение...\")\n",
    "with threadpool_limits(limits=1, user_api='blas'):\n",
    "    als_model.fit(user_item_matrix)\n",
    "print(\" Модель обучена!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "808bf40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Модель сохранена\n"
     ]
    }
   ],
   "source": [
    "# Создаем папку\n",
    "import os\n",
    "\n",
    "os.makedirs(f'{PATH_MODELS}', exist_ok=True)\n",
    "# 7. Сохраняем модель\n",
    "als_model.save(f'{PATH_MODELS}/als_model_final')\n",
    "print(f\" Модель сохранена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5b794ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ТЕСТ РЕКОМЕНДАЦИЙ ===\n",
      "Для товара 65906 похожие товары:\n",
      "  2. Товар 137291 (схожесть: 0.9908)\n",
      "  3. Товар 108791 (схожесть: 0.9809)\n",
      "  4. Товар 153839 (схожесть: 0.9806)\n",
      "  5. Товар 86192 (схожесть: 0.9760)\n"
     ]
    }
   ],
   "source": [
    "# 8. Тестируем рекомендации\n",
    "print(f\"\\n=== ТЕСТ РЕКОМЕНДАЦИЙ ===\")\n",
    "sample_item_id = aggregated_interactions['item_id_enc'].iloc[100]\n",
    "similar_items = als_model.similar_items(sample_item_id, N=5)\n",
    "\n",
    "print(f\"Для товара {sample_item_id} похожие товары:\")\n",
    "for i, (item_id, score) in enumerate(zip(similar_items[0], similar_items[1]), 1):\n",
    "    if item_id != sample_item_id:\n",
    "        print(f\"  {i}. Товар {item_id} (схожесть: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "803e98e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ГЕНЕРИРУЕМ ПОХОЖИЕ ТОВАРЫ ===\n",
      " Похожие товары сохранены\n",
      "\n",
      "Пример для товара 65906:\n",
      "  - Товар 137291 (схожесть: 0.9908)\n",
      "  - Товар 108791 (схожесть: 0.9809)\n",
      "  - Товар 153839 (схожесть: 0.9806)\n",
      "  - Товар 86192 (схожесть: 0.9760)\n",
      "  - Товар 16687 (схожесть: 0.9737)\n"
     ]
    }
   ],
   "source": [
    "# 9. Генерируем похожие товары\n",
    "print(f\"\\n=== ГЕНЕРИРУЕМ ПОХОЖИЕ ТОВАРЫ ===\")\n",
    "\n",
    "train_item_ids_enc = aggregated_interactions['item_id_enc'].unique()\n",
    "similar_items = als_model.similar_items(train_item_ids_enc, N=6)\n",
    "\n",
    "# Создаем DataFrame похожих товаров\n",
    "similar_items_df = pd.DataFrame({\n",
    "    \"item_id_enc\": train_item_ids_enc,\n",
    "    \"sim_item_id_enc\": similar_items[0].tolist(),\n",
    "    \"score\": similar_items[1].tolist()\n",
    "})\n",
    "\n",
    "# Разворачиваем и фильтруем\n",
    "similar_items_df = similar_items_df.explode(['sim_item_id_enc', 'score'])\n",
    "similar_items_df = similar_items_df[similar_items_df['item_id_enc'] != similar_items_df['sim_item_id_enc']]\n",
    "\n",
    "# Сохраняем\n",
    "similar_items_df.to_parquet(f'{PATH_DATA}/recommendations/similar_items.parquet', engine='pyarrow')\n",
    "print(f\" Похожие товары сохранены\")\n",
    "\n",
    "# Тест для примера\n",
    "sample_item = train_item_ids_enc[100]\n",
    "sample_similar = similar_items_df[similar_items_df['item_id_enc'] == sample_item].head(5)\n",
    "print(f\"\\nПример для товара {sample_item}:\")\n",
    "for i, row in sample_similar.iterrows():\n",
    "    print(f\"  - Товар {row['sim_item_id_enc']} (схожесть: {row['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a782b501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id_enc</th>\n",
       "      <th>sim_item_id_enc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26412</td>\n",
       "      <td>124935</td>\n",
       "      <td>0.988801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26412</td>\n",
       "      <td>79876</td>\n",
       "      <td>0.982418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26412</td>\n",
       "      <td>102054</td>\n",
       "      <td>0.978241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26412</td>\n",
       "      <td>58120</td>\n",
       "      <td>0.978169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26412</td>\n",
       "      <td>125356</td>\n",
       "      <td>0.976189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199688</th>\n",
       "      <td>100911</td>\n",
       "      <td>99351</td>\n",
       "      <td>0.885135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199688</th>\n",
       "      <td>100911</td>\n",
       "      <td>14250</td>\n",
       "      <td>0.762263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199688</th>\n",
       "      <td>100911</td>\n",
       "      <td>149604</td>\n",
       "      <td>0.758485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199688</th>\n",
       "      <td>100911</td>\n",
       "      <td>151699</td>\n",
       "      <td>0.752968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199688</th>\n",
       "      <td>100911</td>\n",
       "      <td>139707</td>\n",
       "      <td>0.752218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1003561 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id_enc sim_item_id_enc     score\n",
       "0             26412          124935  0.988801\n",
       "0             26412           79876  0.982418\n",
       "0             26412          102054  0.978241\n",
       "0             26412           58120  0.978169\n",
       "0             26412          125356  0.976189\n",
       "...             ...             ...       ...\n",
       "199688       100911           99351  0.885135\n",
       "199688       100911           14250  0.762263\n",
       "199688       100911          149604  0.758485\n",
       "199688       100911          151699  0.752968\n",
       "199688       100911          139707  0.752218\n",
       "\n",
       "[1003561 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_items_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66b3beeb",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Логируем ALS модель в MLflow\n",
    "\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "EXPERIMENT_NAME = 'project_final_ml'\n",
    "RUN_NAME = 'exp_als_model'\n",
    "\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\" \n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\") \n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "mlflow.set_registry_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "\n",
    "# Проверяем эксперимент\n",
    "try:\n",
    "    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if experiment:\n",
    "        experiment_id = experiment.experiment_id\n",
    "    else:\n",
    "        experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "except Exception as e:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# Логируем\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # Логируем артефакты\n",
    "    mlflow.log_artifact(f'{PATH_DATA}/recommendations/similar_items.parquet')\n",
    "    \n",
    "    # Логируем модель\n",
    "    mlflow.sklearn.log_model(\n",
    "        als_model,\n",
    "        \"als_model\",\n",
    "        registered_model_name=\"als_recommender\"\n",
    "    )\n",
    "    \n",
    "    # Логируем параметры\n",
    "    mlflow.log_param(\"model_type\", \"ALS\")\n",
    "    mlflow.log_param(\"factors\", 64)\n",
    "    mlflow.log_param(\"iterations\", 50)\n",
    "    mlflow.log_param(\"regularization\", 0.05)\n",
    "    mlflow.log_param(\"alpha\", 2.0)\n",
    "    \n",
    "    # Логируем метрики\n",
    "    mlflow.log_metric(\"similar_items_count\", len(similar_items_df))\n",
    "    mlflow.log_metric(\"train_interactions\", len(aggregated_interactions))\n",
    "    mlflow.log_metric(\"train_users\", events_train_clean['visitor_id_enc'].nunique())\n",
    "    mlflow.log_metric(\"train_items\", events_train_clean['item_id_enc'].nunique())\n",
    "    \n",
    "    print(f\" ALS модель залогирована в run: {run_id}\")\n",
    "    print(f\"🔗 MLflow UI: http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "\n",
    "print(f\"\\n ALS МОДЕЛЬ УСПЕШНО ЗАЛОГИРОВАНА В MLFLOW!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e50564d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== УГЛУБЛЕННЫЙ АНАЛИЗ КАЧЕСТВА ===\n",
      "\n",
      "--- ОЦЕНКА NDCG ---\n",
      "Генерируем рекомендации для тестовых пользователей...\n",
      "Обработано 0/500 пользователей\n",
      "Обработано 100/500 пользователей\n",
      "Обработано 200/500 пользователей\n",
      "Обработано 300/500 пользователей\n",
      "Обработано 400/500 пользователей\n",
      "Добавляем истинные оценки...\n",
      "Считаем NDCG@5...\n",
      "NDCG@5: 0.9215\n",
      "Пользователей с оценками: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2369/590776604.py:67: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ndcg_at_5_scores = test_recommendations_df[rating_test_idx].groupby(\"visitor_id_enc\").apply(\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "\n",
    "print(f\"\\n=== УГЛУБЛЕННЫЙ АНАЛИЗ КАЧЕСТВА ===\")\n",
    "\n",
    "# 1. ОЦЕНКА NDCG ДЛЯ РЕКОМЕНДАЦИЙ\n",
    "print(f\"\\n--- ОЦЕНКА NDCG ---\")\n",
    "\n",
    "events_test_clean = pd.read_parquet(f'{PATH_DATA}/events_test_clean.parquet')\n",
    "\n",
    "# Для теста возьмем небольшой набор пользователей из тестовой выборки\n",
    "test_users_sample = events_test_clean['visitor_id_enc'].unique()[:500]  # первые 500 пользователей\n",
    "\n",
    "test_recommendations = []\n",
    "print(\"Генерируем рекомендации для тестовых пользователей...\")\n",
    "\n",
    "for i, user_id in enumerate(test_users_sample):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Обработано {i}/{len(test_users_sample)} пользователей\")\n",
    "    \n",
    "    try:\n",
    "        recommendations = als_model.recommend(\n",
    "            user_id, \n",
    "            user_item_matrix[user_id], \n",
    "            N=10,\n",
    "            filter_already_liked_items=True\n",
    "        )\n",
    "        for item_id, score in zip(recommendations[0], recommendations[1]):\n",
    "            test_recommendations.append({\n",
    "                'visitor_id_enc': user_id,\n",
    "                'item_id_enc': item_id,\n",
    "                'score': score\n",
    "            })\n",
    "    except Exception as e:\n",
    "        # Пропускаем пользователей без взаимодействий в матрице\n",
    "        continue\n",
    "\n",
    "test_recommendations_df = pd.DataFrame(test_recommendations)\n",
    "\n",
    "# Добавляем истинные оценки из тестовой выборки\n",
    "print(\"Добавляем истинные оценки...\")\n",
    "test_recommendations_df = test_recommendations_df.merge(\n",
    "    events_test_clean[[\"visitor_id_enc\", \"item_id_enc\", \"rating\"]]\n",
    "    .rename(columns={\"rating\": \"true_rating\"}), \n",
    "    on=[\"visitor_id_enc\", \"item_id_enc\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Функция для расчета NDCG\n",
    "def compute_ndcg(rating: pd.Series, score: pd.Series, k):\n",
    "    if len(rating) < 2:\n",
    "        return np.nan\n",
    "    try:\n",
    "        ndcg = sklearn.metrics.ndcg_score(\n",
    "            np.asarray([rating.to_numpy()]), \n",
    "            np.asarray([score.to_numpy()]), \n",
    "            k=k\n",
    "        )\n",
    "        return ndcg\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Считаем NDCG@5 для всех пользователей\n",
    "print(\"Считаем NDCG@5...\")\n",
    "rating_test_idx = ~test_recommendations_df[\"true_rating\"].isnull()\n",
    "if rating_test_idx.any():\n",
    "    ndcg_at_5_scores = test_recommendations_df[rating_test_idx].groupby(\"visitor_id_enc\").apply(\n",
    "        lambda x: compute_ndcg(x[\"true_rating\"], x[\"score\"], k=5)\n",
    "    )\n",
    "    ndcg_at_5_mean = ndcg_at_5_scores.mean()\n",
    "    print(f\"NDCG@5: {ndcg_at_5_mean:.4f}\")\n",
    "    print(f\"Пользователей с оценками: {len(ndcg_at_5_scores)}\")\n",
    "else:\n",
    "    ndcg_at_5_mean = 0\n",
    "    print(\"Нет данных для расчета NDCG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4607fc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- АНАЛИЗ ПОХОЖИХ ТОВАРОВ ---\n",
      "Анализируем популярный товар: 2304\n",
      "Топ-10 похожих товаров:\n",
      "  1. Товар 2304 (схожесть: 1.0000)\n",
      "  2. Товар 77245 (схожесть: 0.9997)\n",
      "  3. Товар 183779 (схожесть: 0.9995)\n",
      "  4. Товар 193530 (схожесть: 0.9995)\n",
      "  5. Товар 87019 (схожесть: 0.9995)\n",
      "  6. Товар 169514 (схожесть: 0.9991)\n",
      "  7. Товар 70431 (схожесть: 0.9987)\n",
      "  8. Товар 165979 (схожесть: 0.9987)\n",
      "  9. Товар 62785 (схожесть: 0.9987)\n",
      "  10. Товар 123909 (схожесть: 0.9983)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. АНАЛИЗ ПОХОЖИХ ТОВАРОВ\n",
    "print(f\"\\n--- АНАЛИЗ ПОХОЖИХ ТОВАРОВ ---\")\n",
    "\n",
    "top_items = pd.read_parquet(f'{PATH_DATA}/recommendations/top_popular.parquet')\n",
    "\n",
    "# Берем популярный товар для анализа\n",
    "popular_item_id = top_items['item_id_enc'].iloc[0]\n",
    "print(f\"Анализируем популярный товар: {popular_item_id}\")\n",
    "\n",
    "# Получаем похожие товары\n",
    "similar_items = als_model.similar_items(popular_item_id, N=10)\n",
    "similar_items_analysis = pd.DataFrame({\n",
    "    \"item_id_enc\": similar_items[0],\n",
    "    \"score\": similar_items[1]\n",
    "})\n",
    "\n",
    "print(\"Топ-10 похожих товаров:\")\n",
    "for i, (item_id, score) in enumerate(zip(similar_items[0], similar_items[1])):\n",
    "    print(f\"  {i+1}. Товар {item_id} (схожесть: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70cd2d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- АНАЛИЗ ПОХОЖИХ ПОЛЬЗОВАТЕЛЕЙ ---\n",
      "Анализируем активного пользователя: 786483\n",
      "Похожие пользователи для 786483:\n",
      "  1. Пользователь 786483 (схожесть: 1.0000)\n",
      "  2. Пользователь 295959 (схожесть: 0.9812)\n",
      "  3. Пользователь 926768 (схожесть: 0.9806)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. АНАЛИЗ ПОХОЖИХ ПОЛЬЗОВАТЕЛЕЙ\n",
    "print(f\"\\n--- АНАЛИЗ ПОХОЖИХ ПОЛЬЗОВАТЕЛЕЙ ---\")\n",
    "\n",
    "# Берем активного пользователя\n",
    "active_users = aggregated_interactions['visitor_id_enc'].value_counts()\n",
    "if len(active_users) > 0:\n",
    "    active_user = active_users.index[0]\n",
    "    print(f\"Анализируем активного пользователя: {active_user}\")\n",
    "    \n",
    "    # Получаем похожих пользователей\n",
    "    try:\n",
    "        similar_users = als_model.similar_users(active_user, N=3)\n",
    "        print(f\"Похожие пользователи для {active_user}:\")\n",
    "        for i, (user_id, score) in enumerate(zip(similar_users[0], similar_users[1])):\n",
    "            print(f\"  {i+1}. Пользователь {user_id} (схожесть: {score:.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Не удалось найти похожих пользователей: {e}\")\n",
    "else:\n",
    "    print(\"Нет данных об активных пользователях\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df203a1a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "# 4. ЛОГИРУЕМ ВСЕ МЕТРИКИ В MLFLOW\n",
    "print(f\"\\n--- ОБНОВЛЯЕМ MLFLOW С МЕТРИКАМИ ---\")\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # Логируем артефакты\n",
    "    mlflow.log_artifact(f'{PATH_DATA}/recommendations/similar_items.parquet')\n",
    "    \n",
    "    # Логируем модель\n",
    "    mlflow.sklearn.log_model(\n",
    "        als_model,\n",
    "        \"als_model\",\n",
    "        registered_model_name=\"als_recommender\"\n",
    "    )\n",
    "    \n",
    "    # Логируем параметры\n",
    "    mlflow.log_param(\"model_type\", \"ALS\")\n",
    "    mlflow.log_param(\"factors\", 64)\n",
    "    mlflow.log_param(\"iterations\", 50)\n",
    "    mlflow.log_param(\"regularization\", 0.05)\n",
    "    mlflow.log_param(\"alpha\", 2.0)\n",
    "    mlflow.log_param(\"weights_strategy\", \"enhanced_target_actions\")\n",
    "    \n",
    "    # Логируем метрики качества\n",
    "    mlflow.log_metric(\"ndcg_at_5\", ndcg_at_5_mean)\n",
    "    mlflow.log_metric(\"users_with_ratings\", len(ndcg_at_5_scores) if 'ndcg_at_5_scores' in locals() else 0)\n",
    "    mlflow.log_metric(\"similar_items_count\", len(similar_items_df))\n",
    "    mlflow.log_metric(\"train_interactions\", len(aggregated_interactions))\n",
    "    mlflow.log_metric(\"train_users\", events_train_clean['visitor_id_enc'].nunique())\n",
    "    mlflow.log_metric(\"train_items\", events_train_clean['item_id_enc'].nunique())\n",
    "    \n",
    "    # Логируем распределение весов\n",
    "    weight_stats = events_train_fixed['weight'].value_counts()\n",
    "    mlflow.log_metric(\"weight_view_count\", weight_stats.get(1.0, 0))\n",
    "    mlflow.log_metric(\"weight_addtocart_count\", weight_stats.get(5.0, 0))\n",
    "    mlflow.log_metric(\"weight_transaction_count\", weight_stats.get(10.0, 0))\n",
    "    \n",
    "    print(f\"✅ Все метрики залогированы в run: {run_id}\")\n",
    "\n",
    "print(f\"\\n🎉 УГЛУБЛЕННЫЙ АНАЛИЗ ЗАВЕРШЕН!\")\n",
    "print(f\"📊 NDCG@5: {ndcg_at_5_mean:.4f}\")\n",
    "print(f\"🔗 MLflow UI: http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e0d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ФИНАЛЬНЫЙ АНАЛИЗ КАЧЕСТВА ALS МОДЕЛИ ===\n",
      "\n",
      "--- ОЦЕНКА NDCG НА ОБЩИХ ПОЛЬЗОВАТЕЛЯХ ---\n",
      "Общих пользователей в train/test: 1000\n",
      "Генерируем рекомендации для общих пользователей...\n",
      "Обработано 0/1000 пользователей\n",
      "Обработано 100/1000 пользователей\n",
      "Обработано 200/1000 пользователей\n",
      "Обработано 300/1000 пользователей\n",
      "Обработано 400/1000 пользователей\n",
      "Обработано 500/1000 пользователей\n",
      "Обработано 600/1000 пользователей\n",
      "Обработано 700/1000 пользователей\n",
      "Обработано 800/1000 пользователей\n",
      "Обработано 900/1000 пользователей\n",
      "🎯 NDCG@5: 0.9620\n",
      "👥 Пользователей с оценками: 26\n",
      "\n",
      "--- АНАЛИЗ ПОХОЖИХ ТОВАРОВ ---\n",
      "Анализируем популярный товар: 2304\n",
      "Топ-10 похожих товаров:\n",
      "  1. Товар 2304 (схожесть: 1.0000)\n",
      "  2. Товар 77245 (схожесть: 0.9997)\n",
      "  3. Товар 183779 (схожесть: 0.9995)\n",
      "  4. Товар 193530 (схожесть: 0.9995)\n",
      "  5. Товар 87019 (схожесть: 0.9995)\n",
      "  6. Товар 169514 (схожесть: 0.9991)\n",
      "  7. Товар 70431 (схожесть: 0.9987)\n",
      "  8. Товар 165979 (схожесть: 0.9987)\n",
      "  9. Товар 62785 (схожесть: 0.9987)\n",
      "  10. Товар 123909 (схожесть: 0.9983)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2369/1455617557.py:65: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ndcg_at_5_scores = test_recommendations_df[rating_test_idx].groupby(\"visitor_id_enc\").apply(\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "import numpy as np\n",
    "\n",
    "print(f\"\\n=== ФИНАЛЬНЫЙ АНАЛИЗ КАЧЕСТВА ALS МОДЕЛИ ===\")\n",
    "\n",
    "# Функция для расчета NDCG\n",
    "def compute_ndcg(rating: pd.Series, score: pd.Series, k):\n",
    "    if len(rating) < 2:\n",
    "        return np.nan\n",
    "    try:\n",
    "        ndcg = sklearn.metrics.ndcg_score(\n",
    "            np.asarray([rating.to_numpy()]), \n",
    "            np.asarray([score.to_numpy()]), \n",
    "            k=k\n",
    "        )\n",
    "        return ndcg\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# 1. ОСНОВНОЙ АНАЛИЗ - общие пользователи train/test\n",
    "print(f\"\\n--- ОЦЕНКА NDCG НА ОБЩИХ ПОЛЬЗОВАТЕЛЯХ ---\")\n",
    "common_users = set(events_test_clean['visitor_id_enc']).intersection(\n",
    "    set(events_train_clean['visitor_id_enc'])\n",
    ")\n",
    "common_users = list(common_users)[:1000]\n",
    "\n",
    "print(f\"Общих пользователей в train/test: {len(common_users)}\")\n",
    "\n",
    "test_recommendations = []\n",
    "print(\"Генерируем рекомендации для общих пользователей...\")\n",
    "\n",
    "for i, user_id in enumerate(common_users):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Обработано {i}/{len(common_users)} пользователей\")\n",
    "    \n",
    "    try:\n",
    "        recommendations = als_model.recommend(\n",
    "            user_id, \n",
    "            user_item_matrix[user_id], \n",
    "            N=10,\n",
    "            filter_already_liked_items=True\n",
    "        )\n",
    "        for item_id, score in zip(recommendations[0], recommendations[1]):\n",
    "            test_recommendations.append({\n",
    "                'visitor_id_enc': user_id,\n",
    "                'item_id_enc': item_id,\n",
    "                'score': score\n",
    "            })\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "test_recommendations_df = pd.DataFrame(test_recommendations)\n",
    "\n",
    "# Добавляем истинные оценки\n",
    "test_recommendations_df = test_recommendations_df.merge(\n",
    "    events_test_clean[[\"visitor_id_enc\", \"item_id_enc\", \"rating\"]]\n",
    "    .rename(columns={\"rating\": \"true_rating\"}), \n",
    "    on=[\"visitor_id_enc\", \"item_id_enc\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Считаем NDCG@5\n",
    "rating_test_idx = ~test_recommendations_df[\"true_rating\"].isnull()\n",
    "if rating_test_idx.any():\n",
    "    ndcg_at_5_scores = test_recommendations_df[rating_test_idx].groupby(\"visitor_id_enc\").apply(\n",
    "        lambda x: compute_ndcg(x[\"true_rating\"], x[\"score\"], k=5)\n",
    "    )\n",
    "    ndcg_at_5_mean = ndcg_at_5_scores.mean()\n",
    "    print(f\"🎯 NDCG@5: {ndcg_at_5_mean:.4f}\")\n",
    "    print(f\"👥 Пользователей с оценками: {len(ndcg_at_5_scores)}\")\n",
    "else:\n",
    "    ndcg_at_5_mean = 0\n",
    "    print(\"Нет данных для расчета NDCG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e31b5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- АНАЛИЗ ПОХОЖИХ ТОВАРОВ ---\n",
      "Анализируем популярный товар: 2304\n",
      "Топ-10 похожих товаров:\n",
      "  1. Товар 2304 (схожесть: 1.0000)\n",
      "  2. Товар 77245 (схожесть: 0.9997)\n",
      "  3. Товар 183779 (схожесть: 0.9995)\n",
      "  4. Товар 193530 (схожесть: 0.9995)\n",
      "  5. Товар 87019 (схожесть: 0.9995)\n",
      "  6. Товар 169514 (схожесть: 0.9991)\n",
      "  7. Товар 70431 (схожесть: 0.9987)\n",
      "  8. Товар 165979 (схожесть: 0.9987)\n",
      "  9. Товар 62785 (схожесть: 0.9987)\n",
      "  10. Товар 123909 (схожесть: 0.9983)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. АНАЛИЗ ПОХОЖИХ ТОВАРОВ\n",
    "print(f\"\\n--- АНАЛИЗ ПОХОЖИХ ТОВАРОВ ---\")\n",
    "popular_item_id = top_items['item_id_enc'].iloc[0]\n",
    "print(f\"Анализируем популярный товар: {popular_item_id}\")\n",
    "\n",
    "similar_items = als_model.similar_items(popular_item_id, N=10)\n",
    "print(\"Топ-10 похожих товаров:\")\n",
    "for i, (item_id, score) in enumerate(zip(similar_items[0], similar_items[1])):\n",
    "    print(f\"  {i+1}. Товар {item_id} (схожесть: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76425278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- АНАЛИЗ ПОХОЖИХ ПОЛЬЗОВАТЕЛЕЙ ---\n",
      "Анализируем активного пользователя: 786483\n",
      "Похожие пользователи для 786483:\n",
      "  1. Пользователь 786483 (схожесть: 1.0000)\n",
      "  2. Пользователь 295959 (схожесть: 0.9812)\n",
      "  3. Пользователь 926768 (схожесть: 0.9806)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. АНАЛИЗ ПОХОЖИХ ПОЛЬЗОВАТЕЛЕЙ\n",
    "print(f\"\\n--- АНАЛИЗ ПОХОЖИХ ПОЛЬЗОВАТЕЛЕЙ ---\")\n",
    "active_users = aggregated_interactions['visitor_id_enc'].value_counts()\n",
    "if len(active_users) > 0:\n",
    "    active_user = active_users.index[0]\n",
    "    print(f\"Анализируем активного пользователя: {active_user}\")\n",
    "    \n",
    "    try:\n",
    "        similar_users = als_model.similar_users(active_user, N=3)\n",
    "        print(f\"Похожие пользователи для {active_user}:\")\n",
    "        for i, (user_id, score) in enumerate(zip(similar_users[0], similar_users[1])):\n",
    "            print(f\"  {i+1}. Пользователь {user_id} (схожесть: {score:.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Не удалось найти похожих пользователей: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85740b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ПРОВЕРКА КАЧЕСТВА NDCG ---\n",
      "Распределение NDCG@5:\n",
      "  Мин: 0.7489\n",
      "  Макс: 1.0000\n",
      "  Медиана: 1.0000\n",
      "  Стандартное отклонение: 0.0860\n",
      "\n",
      "Анализ пользователей с оценками:\n",
      "  Среднее событий на пользователя: 107.3\n",
      "  Уникальных товаров: 1599\n",
      "\n",
      "Пересечение товаров train/test: 33,909 из 33,909 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# ДОБАВИМ ПРОВЕРКУ\n",
    "print(f\"\\n--- ПРОВЕРКА КАЧЕСТВА NDCG ---\")\n",
    "\n",
    "# Проверим распределение оценок\n",
    "if 'ndcg_at_5_scores' in locals():\n",
    "    print(f\"Распределение NDCG@5:\")\n",
    "    print(f\"  Мин: {ndcg_at_5_scores.min():.4f}\")\n",
    "    print(f\"  Макс: {ndcg_at_5_scores.max():.4f}\") \n",
    "    print(f\"  Медиана: {ndcg_at_5_scores.median():.4f}\")\n",
    "    print(f\"  Стандартное отклонение: {ndcg_at_5_scores.std():.4f}\")\n",
    "    \n",
    "    # Посмотрим на самих пользователей\n",
    "    print(f\"\\nАнализ пользователей с оценками:\")\n",
    "    user_analysis = events_test_clean[events_test_clean['visitor_id_enc'].isin(ndcg_at_5_scores.index)]\n",
    "    print(f\"  Среднее событий на пользователя: {user_analysis.groupby('visitor_id_enc').size().mean():.1f}\")\n",
    "    print(f\"  Уникальных товаров: {user_analysis['item_id_enc'].nunique()}\")\n",
    "\n",
    "# Проверим пересечения train/test\n",
    "train_items = set(events_train_clean['item_id_enc'])\n",
    "test_items = set(events_test_clean['item_id_enc'])\n",
    "common_items = train_items & test_items\n",
    "print(f\"\\nПересечение товаров train/test: {len(common_items):,} из {len(test_items):,} ({len(common_items)/len(test_items)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacdd085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "790f93ac",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "# 4. ФИНАЛЬНОЕ ЛОГИРОВАНИЕ В MLFLOW\n",
    "print(f\"\\n--- ЛОГИРОВАНИЕ В MLFLOW ---\")\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # Логируем артефакты\n",
    "    mlflow.log_artifact(f'{PATH_DATA}/recommendations/similar_items.parquet')\n",
    "    \n",
    "    # Логируем модель\n",
    "    mlflow.sklearn.log_model(\n",
    "        als_model,\n",
    "        \"als_model\",\n",
    "        registered_model_name=\"als_recommender\"\n",
    "    )\n",
    "    \n",
    "    # Логируем параметры\n",
    "    mlflow.log_param(\"model_type\", \"ALS\")\n",
    "    mlflow.log_param(\"factors\", 64)\n",
    "    mlflow.log_param(\"iterations\", 50)\n",
    "    mlflow.log_param(\"regularization\", 0.05)\n",
    "    mlflow.log_param(\"alpha\", 2.0)\n",
    "    mlflow.log_param(\"weights_strategy\", \"enhanced_target_actions\")\n",
    "    \n",
    "    # Логируем ОСНОВНЫЕ метрики\n",
    "    mlflow.log_metric(\"ndcg_at_5\", ndcg_at_5_mean)\n",
    "    mlflow.log_metric(\"users_with_ratings\", len(ndcg_at_5_scores))\n",
    "    mlflow.log_metric(\"similar_items_count\", len(similar_items_df))\n",
    "    mlflow.log_metric(\"train_interactions\", len(aggregated_interactions))\n",
    "    mlflow.log_metric(\"train_users\", events_train_clean['visitor_id_enc'].nunique())\n",
    "    mlflow.log_metric(\"train_items\", events_train_clean['item_id_enc'].nunique())\n",
    "    \n",
    "    print(f\"✅ Все метрики залогированы в run: {run_id}\")\n",
    "\n",
    "print(f\"\\n🎉 ФИНАЛЬНЫЙ АНАЛИЗ ЗАВЕРШЕН!\")\n",
    "print(f\"📊 NDCG@5: {ndcg_at_5_mean:.4f} (на {len(ndcg_at_5_scores)} пользователях)\")\n",
    "print(f\"🔗 MLflow UI: http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dadacf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a01484a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e288e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf4c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c577f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705e7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bfd1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_final_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
